//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-27506705
// Cuda compilation tools, release 10.2, V10.2.89
// Based on LLVM 3.4svn
//

.version 6.5
.target sm_30, debug
.address_size 64

	// .globl	_Z11complexSqrt7double2
.func  (.param .b64 func_retval0) sqrt
(
	.param .b64 sqrt_param_0
)
;
.func  (.param .b64 func_retval0) sin
(
	.param .b64 sin_param_0
)
;
.func  (.param .b64 func_retval0) cos
(
	.param .b64 cos_param_0
)
;
.func  (.param .b64 func_retval0) exp
(
	.param .b64 exp_param_0
)
;
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
.const .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};
.const .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};

.visible .func  (.param .align 16 .b8 func_retval0[16]) _Z11complexSqrt7double2(
	.param .align 16 .b8 _Z11complexSqrt7double2_param_0[16]
)
{
	.local .align 16 .b8 	__local_depot0[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .f64 	%fd<30>;


	.loc 1 51 1
func_begin0:
	.loc	1 0 0

	.loc 1 51 1

	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd2, [_Z11complexSqrt7double2_param_0+8];
	ld.param.f64 	%fd1, [_Z11complexSqrt7double2_param_0];
	st.f64 	[%SP+8], %fd2;
	st.f64 	[%SP+0], %fd1;
func_exec_begin0:
	.loc	1 54 5
tmp0:
	ld.f64 	%fd3, [%SP+0];
	ld.f64 	%fd4, [%SP+0];
	mul.f64 	%fd5, %fd3, %fd4;
	ld.f64 	%fd6, [%SP+8];
	ld.f64 	%fd7, [%SP+8];
	mul.f64 	%fd8, %fd6, %fd7;
	add.f64 	%fd9, %fd5, %fd8;
	.loc	1 54 9
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd9;
	.param .b64 retval0;
	call.uni (retval0), 
	sqrt, 
	(
	param0
	);
	ld.param.f64	%fd10, [retval0+0];
	
	//{
	}// Callseq End 0
tmp1:
	.loc	1 55 13
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd10;
	.param .b64 retval0;
	call.uni (retval0), 
	sqrt, 
	(
	param0
	);
	ld.param.f64	%fd11, [retval0+0];
	
	//{
	}// Callseq End 1
	ld.f64 	%fd12, [%SP+0];
	add.f64 	%fd13, %fd10, %fd12;
	ld.f64 	%fd14, [%SP+0];
	add.f64 	%fd15, %fd10, %fd14;
	mul.f64 	%fd16, %fd13, %fd15;
	ld.f64 	%fd17, [%SP+8];
	ld.f64 	%fd18, [%SP+8];
	mul.f64 	%fd19, %fd17, %fd18;
	add.f64 	%fd20, %fd16, %fd19;
	.loc	1 55 24
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd20;
	.param .b64 retval0;
	call.uni (retval0), 
	sqrt, 
	(
	param0
	);
	ld.param.f64	%fd21, [retval0+0];
	
	//{
	}// Callseq End 2
	div.rn.f64 	%fd22, %fd11, %fd21;
tmp2:
	.loc	1 56 5
	ld.f64 	%fd23, [%SP+0];
	add.f64 	%fd24, %fd23, %fd10;
	mul.f64 	%fd25, %fd22, %fd24;
	st.f64 	[%SP+0], %fd25;
	.loc	1 57 5
	ld.f64 	%fd26, [%SP+8];
	mul.f64 	%fd27, %fd22, %fd26;
	st.f64 	[%SP+8], %fd27;
	.loc	1 58 5
	ld.f64 	%fd28, [%SP+8];
	ld.f64 	%fd29, [%SP+0];
	st.param.f64	[func_retval0+0], %fd29;
	st.param.f64	[func_retval0+8], %fd28;
	ret;
tmp3:
func_end0:
}

	// .globl	_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2_
.visible .entry _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2_(
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_0,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_1,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_2,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_3,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_4,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_5,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_6,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_7,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_8,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_9,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_10,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_11,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_12,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_13,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_14,
	.param .u64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_15
)
{
	.local .align 16 .b8 	__local_depot1[576];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<11>;
	.reg .b32 	%r<87>;
	.reg .f64 	%fd<234>;
	.reg .b64 	%rd<53>;


	.loc 1 76 1
func_begin1:
	.loc	1 0 0

	.loc 1 76 1

	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_0];
	ld.param.u64 	%rd2, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_1];
	ld.param.u64 	%rd3, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_2];
	ld.param.u64 	%rd4, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_3];
	ld.param.u64 	%rd5, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_4];
	ld.param.u64 	%rd6, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_5];
	ld.param.u64 	%rd7, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_6];
	ld.param.u64 	%rd8, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_7];
	ld.param.u64 	%rd9, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_8];
	ld.param.u64 	%rd10, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_9];
	ld.param.u64 	%rd11, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_10];
	ld.param.u64 	%rd12, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_11];
	ld.param.u64 	%rd13, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_12];
	ld.param.u64 	%rd14, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_13];
	ld.param.u64 	%rd15, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_14];
	ld.param.u64 	%rd16, [_Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_15];
tmp4:
func_exec_begin1:
	.loc	1 80 14
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %ntid.x;
	mul.lo.s32 	%r9, %r7, %r8;
	mov.u32 	%r10, %tid.x;
	add.s32 	%r1, %r9, %r10;
tmp5:
	.loc	1 81 5
	ld.u32 	%r11, [%rd2];
	ld.u32 	%r12, [%rd2+4];
	mul.lo.s32 	%r13, %r11, %r12;
	ld.u32 	%r14, [%rd2+8];
	mul.lo.s32 	%r15, %r13, %r14;
	setp.ge.s32	%p1, %r1, %r15;
	not.pred 	%p2, %p1;
	@%p2 bra 	BB1_2;
	bra.uni 	BB1_1;

BB1_1:
	.loc	1 82 9
tmp6:
	bra.uni 	BB1_7;
tmp7:

BB1_2:
	.loc	1 84 5
	ld.u32 	%r16, [%rd2];
	ld.u32 	%r17, [%rd2+4];
	mul.lo.s32 	%r18, %r16, %r17;
	div.s32 	%r19, %r1, %r18;
	st.u32 	[%SP+552], %r19;
	.loc	1 85 5
	ld.u32 	%r20, [%SP+552];
	ld.u32 	%r21, [%rd2];
	ld.u32 	%r22, [%rd2+4];
	mul.lo.s32 	%r23, %r21, %r22;
	mul.lo.s32 	%r24, %r20, %r23;
	sub.s32 	%r25, %r1, %r24;
	ld.u32 	%r26, [%rd2];
	div.s32 	%r27, %r25, %r26;
	st.u32 	[%SP+548], %r27;
	.loc	1 86 5
	ld.u32 	%r28, [%rd2];
	rem.s32 	%r29, %r1, %r28;
	st.u32 	[%SP+544], %r29;
	.loc	1 87 16
	ld.u32 	%r30, [%rd10+4];
	setp.gt.s32	%p3, %r30, 1;
	selp.u32	%r31, 1, 0, %p3;
	ld.u32 	%r32, [%SP+544];
	mul.lo.s32 	%r33, %r31, %r32;
	ld.u32 	%r34, [%rd10+4];
	ld.u32 	%r35, [%rd10+8];
	setp.gt.s32	%p4, %r35, 1;
	selp.u32	%r36, 1, 0, %p4;
	mul.lo.s32 	%r37, %r34, %r36;
	ld.u32 	%r38, [%SP+548];
	mul.lo.s32 	%r39, %r37, %r38;
	add.s32 	%r40, %r33, %r39;
	ld.u32 	%r41, [%rd10+4];
	ld.u32 	%r42, [%rd10+8];
	mul.lo.s32 	%r43, %r41, %r42;
	ld.u32 	%r44, [%rd10+12];
	setp.gt.s32	%p5, %r44, 1;
	selp.u32	%r45, 1, 0, %p5;
	mul.lo.s32 	%r46, %r43, %r45;
	ld.u32 	%r47, [%SP+552];
	mul.lo.s32 	%r48, %r46, %r47;
	add.s32 	%r2, %r40, %r48;
tmp8:
	.loc	1 88 14
	ld.u32 	%r49, [%rd5+4];
	setp.gt.s32	%p6, %r49, 1;
	selp.u32	%r50, 1, 0, %p6;
	ld.u32 	%r51, [%SP+544];
	mul.lo.s32 	%r52, %r50, %r51;
	ld.u32 	%r53, [%rd5+4];
	ld.u32 	%r54, [%rd5+8];
	setp.gt.s32	%p7, %r54, 1;
	selp.u32	%r55, 1, 0, %p7;
	mul.lo.s32 	%r56, %r53, %r55;
	ld.u32 	%r57, [%SP+548];
	mul.lo.s32 	%r58, %r56, %r57;
	add.s32 	%r59, %r52, %r58;
	ld.u32 	%r60, [%rd5+4];
	ld.u32 	%r61, [%rd5+8];
	mul.lo.s32 	%r62, %r60, %r61;
	ld.u32 	%r63, [%rd5+12];
	setp.gt.s32	%p8, %r63, 1;
	selp.u32	%r64, 1, 0, %p8;
	mul.lo.s32 	%r65, %r62, %r64;
	ld.u32 	%r66, [%SP+552];
	mul.lo.s32 	%r67, %r65, %r66;
	add.s32 	%r3, %r59, %r67;
tmp9:
	.loc	1 91 25
	mov.u32 	%r68, 0;
	mov.b32 	%r4, %r68;
tmp10:
	mov.u32 	%r86, %r4;
tmp11:

BB1_3:
	.loc	1 91 5
	mov.u32 	%r5, %r86;
tmp12:
	ld.u32 	%r69, [%rd16];
	setp.lt.s32	%p9, %r5, %r69;
	not.pred 	%p10, %p9;
	@%p10 bra 	BB1_6;
	bra.uni 	BB1_4;

BB1_4:
	.loc	1 93 9
tmp13:
	cvt.s64.s32	%rd17, %r2;
	shl.b64 	%rd18, %rd17, 4;
	add.s64 	%rd19, %rd6, %rd18;
	ld.f64 	%fd1, [%rd19];
	ld.f64 	%fd2, [%rd19+8];
	cvt.s64.s32	%rd20, %r5;
	shl.b64 	%rd21, %rd20, 4;
	add.s64 	%rd22, %rd11, %rd21;
	ld.f64 	%fd3, [%rd22];
	ld.f64 	%fd4, [%rd22+8];
	st.f64 	[%SP+536], %fd4;
	st.f64 	[%SP+528], %fd3;
	.loc	1 93 61
	bra.uni	tmp14;
tmp14:
	.loc	1 72 5
	ld.f64 	%fd5, [%SP+536];
	neg.f64 	%fd6, %fd5;
	st.f64 	[%SP+536], %fd6;
	.loc	1 73 5
	ld.f64 	%fd7, [%SP+528];
	ld.f64 	%fd8, [%SP+536];
	st.f64 	[%SP+312], %fd2;
	st.f64 	[%SP+304], %fd1;
	st.f64 	[%SP+328], %fd8;
	st.f64 	[%SP+320], %fd7;
tmp15:
	.loc	1 93 44
	bra.uni	tmp16;
tmp16:
	.loc	1 8 5
	ld.f64 	%fd9, [%SP+304];
	ld.f64 	%fd10, [%SP+320];
	add.f64 	%fd11, %fd9, %fd10;
	st.f64 	[%SP+304], %fd11;
	.loc	1 9 5
	ld.f64 	%fd12, [%SP+312];
	ld.f64 	%fd13, [%SP+328];
	add.f64 	%fd14, %fd12, %fd13;
	st.f64 	[%SP+312], %fd14;
	.loc	1 10 5
	ld.f64 	%fd15, [%SP+304];
	ld.f64 	%fd16, [%SP+312];
	st.f64 	[%SP+296], %fd16;
	st.f64 	[%SP+288], %fd15;
tmp17:
	.loc	1 93 30
	bra.uni	tmp18;
tmp18:
	.loc	1 45 28
	ld.f64 	%fd17, [%SP+288];
	mov.f64 	%fd18, %fd17;
tmp19:
	.loc	1 46 5
	ld.f64 	%fd19, [%SP+288];
	ld.f64 	%fd20, [%SP+296];
	sub.f64 	%fd21, %fd19, %fd20;
	ld.f64 	%fd22, [%SP+288];
	ld.f64 	%fd23, [%SP+296];
	add.f64 	%fd24, %fd22, %fd23;
	mul.f64 	%fd25, %fd21, %fd24;
	st.f64 	[%SP+288], %fd25;
	.loc	1 47 5
	mul.f64 	%fd26, %fd18, 0d4000000000000000;
	ld.f64 	%fd27, [%SP+296];
	mul.f64 	%fd28, %fd26, %fd27;
	st.f64 	[%SP+296], %fd28;
	.loc	1 48 5
	ld.f64 	%fd29, [%SP+288];
	ld.f64 	%fd30, [%SP+296];
tmp20:
	.loc	1 93 30
	cvt.s64.s32	%rd23, %r2;
	shl.b64 	%rd24, %rd23, 4;
	add.s64 	%rd25, %rd7, %rd24;
	ld.f64 	%fd31, [%rd25];
	ld.f64 	%fd32, [%rd25+8];
	cvt.s64.s32	%rd26, %r5;
	shl.b64 	%rd27, %rd26, 4;
	add.s64 	%rd28, %rd12, %rd27;
	ld.f64 	%fd33, [%rd28];
	ld.f64 	%fd34, [%rd28+8];
	st.f64 	[%SP+280], %fd34;
	st.f64 	[%SP+272], %fd33;
	.loc	1 94 61
	bra.uni	tmp21;
tmp21:
	.loc	1 72 5
	ld.f64 	%fd35, [%SP+280];
	neg.f64 	%fd36, %fd35;
	st.f64 	[%SP+280], %fd36;
	.loc	1 73 5
	ld.f64 	%fd37, [%SP+272];
	ld.f64 	%fd38, [%SP+280];
	st.f64 	[%SP+152], %fd32;
	st.f64 	[%SP+144], %fd31;
	st.f64 	[%SP+168], %fd38;
	st.f64 	[%SP+160], %fd37;
tmp22:
	.loc	1 94 44
	bra.uni	tmp23;
tmp23:
	.loc	1 8 5
	ld.f64 	%fd39, [%SP+144];
	ld.f64 	%fd40, [%SP+160];
	add.f64 	%fd41, %fd39, %fd40;
	st.f64 	[%SP+144], %fd41;
	.loc	1 9 5
	ld.f64 	%fd42, [%SP+152];
	ld.f64 	%fd43, [%SP+168];
	add.f64 	%fd44, %fd42, %fd43;
	st.f64 	[%SP+152], %fd44;
	.loc	1 10 5
	ld.f64 	%fd45, [%SP+144];
	ld.f64 	%fd46, [%SP+152];
	st.f64 	[%SP+8], %fd46;
	st.f64 	[%SP+0], %fd45;
tmp24:
	.loc	1 94 30
	bra.uni	tmp25;
tmp25:
	.loc	1 45 28
	ld.f64 	%fd47, [%SP+0];
	mov.f64 	%fd48, %fd47;
tmp26:
	.loc	1 46 5
	ld.f64 	%fd49, [%SP+0];
	ld.f64 	%fd50, [%SP+8];
	sub.f64 	%fd51, %fd49, %fd50;
	ld.f64 	%fd52, [%SP+0];
	ld.f64 	%fd53, [%SP+8];
	add.f64 	%fd54, %fd52, %fd53;
	mul.f64 	%fd55, %fd51, %fd54;
	st.f64 	[%SP+0], %fd55;
	.loc	1 47 5
	mul.f64 	%fd56, %fd48, 0d4000000000000000;
	ld.f64 	%fd57, [%SP+8];
	mul.f64 	%fd58, %fd56, %fd57;
	st.f64 	[%SP+8], %fd58;
	.loc	1 48 5
	ld.f64 	%fd59, [%SP+0];
	ld.f64 	%fd60, [%SP+8];
	st.f64 	[%SP+24], %fd30;
	st.f64 	[%SP+16], %fd29;
	st.f64 	[%SP+40], %fd60;
	st.f64 	[%SP+32], %fd59;
tmp27:
	.loc	1 93 30
	bra.uni	tmp28;
tmp28:
	.loc	1 8 5
	ld.f64 	%fd61, [%SP+16];
	ld.f64 	%fd62, [%SP+32];
	add.f64 	%fd63, %fd61, %fd62;
	st.f64 	[%SP+16], %fd63;
	.loc	1 9 5
	ld.f64 	%fd64, [%SP+24];
	ld.f64 	%fd65, [%SP+40];
	add.f64 	%fd66, %fd64, %fd65;
	st.f64 	[%SP+24], %fd66;
	.loc	1 10 5
	ld.f64 	%fd67, [%SP+16];
	ld.f64 	%fd68, [%SP+24];
tmp29:
	.loc	1 93 30
	cvt.s64.s32	%rd29, %r2;
	shl.b64 	%rd30, %rd29, 4;
	add.s64 	%rd31, %rd8, %rd30;
	ld.f64 	%fd69, [%rd31];
	ld.f64 	%fd70, [%rd31+8];
	cvt.s64.s32	%rd32, %r5;
	shl.b64 	%rd33, %rd32, 4;
	add.s64 	%rd34, %rd13, %rd33;
	ld.f64 	%fd71, [%rd34];
	ld.f64 	%fd72, [%rd34+8];
	st.f64 	[%SP+56], %fd72;
	st.f64 	[%SP+48], %fd71;
	.loc	1 95 61
	bra.uni	tmp30;
tmp30:
	.loc	1 72 5
	ld.f64 	%fd73, [%SP+56];
	neg.f64 	%fd74, %fd73;
	st.f64 	[%SP+56], %fd74;
	.loc	1 73 5
	ld.f64 	%fd75, [%SP+48];
	ld.f64 	%fd76, [%SP+56];
	st.f64 	[%SP+72], %fd70;
	st.f64 	[%SP+64], %fd69;
	st.f64 	[%SP+88], %fd76;
	st.f64 	[%SP+80], %fd75;
tmp31:
	.loc	1 95 44
	bra.uni	tmp32;
tmp32:
	.loc	1 8 5
	ld.f64 	%fd77, [%SP+64];
	ld.f64 	%fd78, [%SP+80];
	add.f64 	%fd79, %fd77, %fd78;
	st.f64 	[%SP+64], %fd79;
	.loc	1 9 5
	ld.f64 	%fd80, [%SP+72];
	ld.f64 	%fd81, [%SP+88];
	add.f64 	%fd82, %fd80, %fd81;
	st.f64 	[%SP+72], %fd82;
	.loc	1 10 5
	ld.f64 	%fd83, [%SP+64];
	ld.f64 	%fd84, [%SP+72];
	st.f64 	[%SP+104], %fd84;
	st.f64 	[%SP+96], %fd83;
tmp33:
	.loc	1 95 30
	bra.uni	tmp34;
tmp34:
	.loc	1 45 28
	ld.f64 	%fd85, [%SP+96];
	mov.f64 	%fd86, %fd85;
tmp35:
	.loc	1 46 5
	ld.f64 	%fd87, [%SP+96];
	ld.f64 	%fd88, [%SP+104];
	sub.f64 	%fd89, %fd87, %fd88;
	ld.f64 	%fd90, [%SP+96];
	ld.f64 	%fd91, [%SP+104];
	add.f64 	%fd92, %fd90, %fd91;
	mul.f64 	%fd93, %fd89, %fd92;
	st.f64 	[%SP+96], %fd93;
	.loc	1 47 5
	mul.f64 	%fd94, %fd86, 0d4000000000000000;
	ld.f64 	%fd95, [%SP+104];
	mul.f64 	%fd96, %fd94, %fd95;
	st.f64 	[%SP+104], %fd96;
	.loc	1 48 5
	ld.f64 	%fd97, [%SP+96];
	ld.f64 	%fd98, [%SP+104];
	st.f64 	[%SP+120], %fd68;
	st.f64 	[%SP+112], %fd67;
	st.f64 	[%SP+136], %fd98;
	st.f64 	[%SP+128], %fd97;
tmp36:
	.loc	1 93 30
	bra.uni	tmp37;
tmp37:
	.loc	1 8 5
	ld.f64 	%fd99, [%SP+112];
	ld.f64 	%fd100, [%SP+128];
	add.f64 	%fd101, %fd99, %fd100;
	st.f64 	[%SP+112], %fd101;
	.loc	1 9 5
	ld.f64 	%fd102, [%SP+120];
	ld.f64 	%fd103, [%SP+136];
	add.f64 	%fd104, %fd102, %fd103;
	st.f64 	[%SP+120], %fd104;
	.loc	1 10 5
	ld.f64 	%fd105, [%SP+120];
	ld.f64 	%fd106, [%SP+112];
tmp38:
	.loc	1 93 18
	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .align 16 .b8 param0[16];
	st.param.f64	[param0+0], %fd106;
	st.param.f64	[param0+8], %fd105;
	.param .align 16 .b8 retval0[16];
	call.uni (retval0), 
	_Z11complexSqrt7double2, 
	(
	param0
	);
	ld.param.f64	%fd107, [retval0+0];
	ld.param.f64	%fd108, [retval0+8];
	
	//{
	}// Callseq End 3
	st.f64 	[%SP+568], %fd108;
	st.f64 	[%SP+560], %fd107;
	.loc	1 96 9
	cvt.s64.s32	%rd35, %r1;
	shl.b64 	%rd36, %rd35, 4;
	add.s64 	%rd37, %rd1, %rd36;
	cvt.s64.s32	%rd38, %r1;
	shl.b64 	%rd39, %rd38, 4;
	add.s64 	%rd40, %rd1, %rd39;
	ld.f64 	%fd109, [%rd40];
	ld.f64 	%fd110, [%rd40+8];
	cvt.s64.s32	%rd41, %r5;
	shl.b64 	%rd42, %rd41, 3;
	add.s64 	%rd43, %rd15, %rd42;
	ld.f64 	%fd111, [%rd43];
	mul.f64 	%fd112, %fd111, 0d4000000000000000;
	mul.f64 	%fd113, %fd112, 0d400921FB54442D18;
	ld.f64 	%fd114, [%rd3];
tmp39:
	ld.f64 	%fd115, [%rd3+8];
	st.f64 	[%SP+184], %fd115;
	st.f64 	[%SP+176], %fd114;
	.loc	1 96 30
	bra.uni	tmp40;
tmp40:
	.loc	1 29 5
	ld.f64 	%fd116, [%SP+176];
	mul.f64 	%fd117, %fd116, %fd113;
	st.f64 	[%SP+176], %fd117;
	.loc	1 30 5
	ld.f64 	%fd118, [%SP+184];
	mul.f64 	%fd119, %fd118, %fd113;
	st.f64 	[%SP+184], %fd119;
	.loc	1 31 5
	ld.f64 	%fd120, [%SP+176];
	ld.f64 	%fd121, [%SP+184];
tmp41:
	.loc	1 96 30
	cvt.s64.s32	%rd44, %r3;
	shl.b64 	%rd45, %rd44, 4;
	add.s64 	%rd46, %rd4, %rd45;
	ld.f64 	%fd122, [%rd46];
	ld.f64 	%fd123, [%rd46+8];
	cvt.s64.s32	%rd47, %r2;
	shl.b64 	%rd48, %rd47, 4;
	add.s64 	%rd49, %rd9, %rd48;
	ld.f64 	%fd124, [%rd49];
	ld.f64 	%fd125, [%rd49+8];
	cvt.s64.s32	%rd50, %r5;
	shl.b64 	%rd51, %rd50, 4;
	add.s64 	%rd52, %rd14, %rd51;
	ld.f64 	%fd126, [%rd52];
	ld.f64 	%fd127, [%rd52+8];
	st.f64 	[%SP+200], %fd127;
	st.f64 	[%SP+192], %fd126;
	.loc	1 96 143
	bra.uni	tmp42;
tmp42:
	.loc	1 72 5
	ld.f64 	%fd128, [%SP+200];
	neg.f64 	%fd129, %fd128;
	st.f64 	[%SP+200], %fd129;
	.loc	1 73 5
	ld.f64 	%fd130, [%SP+192];
	ld.f64 	%fd131, [%SP+200];
	st.f64 	[%SP+216], %fd125;
	st.f64 	[%SP+208], %fd124;
	st.f64 	[%SP+232], %fd131;
	st.f64 	[%SP+224], %fd130;
tmp43:
	.loc	1 96 128
	bra.uni	tmp44;
tmp44:
	.loc	1 8 5
	ld.f64 	%fd132, [%SP+208];
	ld.f64 	%fd133, [%SP+224];
	add.f64 	%fd134, %fd132, %fd133;
	st.f64 	[%SP+208], %fd134;
	.loc	1 9 5
	ld.f64 	%fd135, [%SP+216];
	ld.f64 	%fd136, [%SP+232];
	add.f64 	%fd137, %fd135, %fd136;
	st.f64 	[%SP+216], %fd137;
	.loc	1 10 5
	ld.f64 	%fd138, [%SP+208];
	ld.f64 	%fd139, [%SP+216];
tmp45:
	.loc	1 96 128
	ld.f64 	%fd140, [%SP+560];
	ld.f64 	%fd141, [%SP+568];
	st.f64 	[%SP+248], %fd139;
	st.f64 	[%SP+240], %fd138;
	st.f64 	[%SP+264], %fd141;
	st.f64 	[%SP+256], %fd140;
	.loc	1 96 128
	bra.uni	tmp46;
tmp46:
	.loc	1 8 5
	ld.f64 	%fd142, [%SP+240];
	ld.f64 	%fd143, [%SP+256];
	add.f64 	%fd144, %fd142, %fd143;
	st.f64 	[%SP+240], %fd144;
	.loc	1 9 5
	ld.f64 	%fd145, [%SP+248];
	ld.f64 	%fd146, [%SP+264];
	add.f64 	%fd147, %fd145, %fd146;
	st.f64 	[%SP+248], %fd147;
	.loc	1 10 5
	ld.f64 	%fd148, [%SP+240];
	ld.f64 	%fd149, [%SP+248];
	st.f64 	[%SP+344], %fd149;
	st.f64 	[%SP+336], %fd148;
tmp47:
	.loc	1 96 112
	bra.uni	tmp48;
tmp48:
	.loc	1 64 5
	ld.f64 	%fd150, [%SP+336];
	.loc	1 64 12
	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd150;
	.param .b64 retval0;
	call.uni (retval0), 
	exp, 
	(
	param0
	);
	ld.param.f64	%fd151, [retval0+0];
	
	//{
	}// Callseq End 4
tmp49:
	.loc	1 65 5
	ld.f64 	%fd152, [%SP+344];
	.loc	1 65 18
	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd152;
	.param .b64 retval0;
	call.uni (retval0), 
	cos, 
	(
	param0
	);
	ld.param.f64	%fd153, [retval0+0];
	
	//{
	}// Callseq End 5
	mul.f64 	%fd154, %fd151, %fd153;
	st.f64 	[%SP+336], %fd154;
	.loc	1 66 5
	ld.f64 	%fd155, [%SP+344];
	.loc	1 66 18
	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd155;
	.param .b64 retval0;
	call.uni (retval0), 
	sin, 
	(
	param0
	);
	ld.param.f64	%fd156, [retval0+0];
	
	//{
	}// Callseq End 6
	mul.f64 	%fd157, %fd151, %fd156;
	st.f64 	[%SP+344], %fd157;
	.loc	1 67 5
	ld.f64 	%fd158, [%SP+336];
	ld.f64 	%fd159, [%SP+344];
	st.f64 	[%SP+360], %fd123;
	st.f64 	[%SP+352], %fd122;
	st.f64 	[%SP+376], %fd159;
	st.f64 	[%SP+368], %fd158;
tmp50:
	.loc	1 96 101
	bra.uni	tmp51;
tmp51:
	.loc	1 36 29
	ld.v4.u32 	{%r70, %r71, %r72, %r73}, [%SP+352];
	st.v4.u32 	[%SP+384], {%r70, %r71, %r72, %r73};
	.loc	1 38 5
	ld.f64 	%fd160, [%SP+352];
	ld.f64 	%fd161, [%SP+368];
	mul.f64 	%fd162, %fd160, %fd161;
	ld.f64 	%fd163, [%SP+360];
	ld.f64 	%fd164, [%SP+376];
	mul.f64 	%fd165, %fd163, %fd164;
	sub.f64 	%fd166, %fd162, %fd165;
	st.f64 	[%SP+352], %fd166;
	.loc	1 39 5
	ld.f64 	%fd167, [%SP+384];
	ld.f64 	%fd168, [%SP+376];
	mul.f64 	%fd169, %fd167, %fd168;
	ld.f64 	%fd170, [%SP+392];
	ld.f64 	%fd171, [%SP+368];
	mul.f64 	%fd172, %fd170, %fd171;
	add.f64 	%fd173, %fd169, %fd172;
	st.f64 	[%SP+360], %fd173;
	.loc	1 40 5
	ld.f64 	%fd174, [%SP+352];
	ld.f64 	%fd175, [%SP+360];
tmp52:
	.loc	1 96 101
	ld.f64 	%fd176, [%SP+560];
	ld.f64 	%fd177, [%SP+568];
	st.f64 	[%SP+408], %fd175;
	st.f64 	[%SP+400], %fd174;
	st.f64 	[%SP+424], %fd177;
	st.f64 	[%SP+416], %fd176;
	.loc	1 96 101
	bra.uni	tmp53;
tmp53:
	.loc	1 22 5
	ld.f64 	%fd178, [%SP+400];
	ld.f64 	%fd179, [%SP+416];
	mul.f64 	%fd180, %fd178, %fd179;
	ld.f64 	%fd181, [%SP+408];
	ld.f64 	%fd182, [%SP+424];
	mul.f64 	%fd183, %fd181, %fd182;
	add.f64 	%fd184, %fd180, %fd183;
	ld.f64 	%fd185, [%SP+416];
	ld.f64 	%fd186, [%SP+416];
	mul.f64 	%fd187, %fd185, %fd186;
	ld.f64 	%fd188, [%SP+424];
	ld.f64 	%fd189, [%SP+424];
	mul.f64 	%fd190, %fd188, %fd189;
	add.f64 	%fd191, %fd187, %fd190;
	div.rn.f64 	%fd192, %fd184, %fd191;
	st.f64 	[%SP+432], %fd192;
	.loc	1 23 5
	ld.f64 	%fd193, [%SP+408];
	ld.f64 	%fd194, [%SP+416];
	mul.f64 	%fd195, %fd193, %fd194;
	ld.f64 	%fd196, [%SP+400];
	ld.f64 	%fd197, [%SP+424];
	mul.f64 	%fd198, %fd196, %fd197;
	sub.f64 	%fd199, %fd195, %fd198;
	ld.f64 	%fd200, [%SP+416];
	ld.f64 	%fd201, [%SP+416];
	mul.f64 	%fd202, %fd200, %fd201;
	ld.f64 	%fd203, [%SP+424];
	ld.f64 	%fd204, [%SP+424];
	mul.f64 	%fd205, %fd203, %fd204;
	add.f64 	%fd206, %fd202, %fd205;
	div.rn.f64 	%fd207, %fd199, %fd206;
	st.f64 	[%SP+440], %fd207;
	.loc	1 24 5
	ld.f64 	%fd208, [%SP+432];
	ld.f64 	%fd209, [%SP+440];
	st.f64 	[%SP+456], %fd121;
	st.f64 	[%SP+448], %fd120;
	st.f64 	[%SP+472], %fd209;
	st.f64 	[%SP+464], %fd208;
tmp54:
	.loc	1 96 29
	bra.uni	tmp55;
tmp55:
	.loc	1 36 29
	ld.v4.u32 	{%r78, %r79, %r80, %r81}, [%SP+448];
	st.v4.u32 	[%SP+480], {%r78, %r79, %r80, %r81};
	.loc	1 38 5
	ld.f64 	%fd210, [%SP+448];
	ld.f64 	%fd211, [%SP+464];
	mul.f64 	%fd212, %fd210, %fd211;
	ld.f64 	%fd213, [%SP+456];
	ld.f64 	%fd214, [%SP+472];
	mul.f64 	%fd215, %fd213, %fd214;
	sub.f64 	%fd216, %fd212, %fd215;
	st.f64 	[%SP+448], %fd216;
	.loc	1 39 5
	ld.f64 	%fd217, [%SP+480];
	ld.f64 	%fd218, [%SP+472];
	mul.f64 	%fd219, %fd217, %fd218;
	ld.f64 	%fd220, [%SP+488];
	ld.f64 	%fd221, [%SP+464];
	mul.f64 	%fd222, %fd220, %fd221;
	add.f64 	%fd223, %fd219, %fd222;
	st.f64 	[%SP+456], %fd223;
	.loc	1 40 5
	ld.f64 	%fd224, [%SP+448];
	ld.f64 	%fd225, [%SP+456];
	st.f64 	[%SP+504], %fd110;
	st.f64 	[%SP+496], %fd109;
	st.f64 	[%SP+520], %fd225;
	st.f64 	[%SP+512], %fd224;
tmp56:
	.loc	1 96 19
	bra.uni	tmp57;
tmp57:
	.loc	1 8 5
	ld.f64 	%fd226, [%SP+496];
	ld.f64 	%fd227, [%SP+512];
	add.f64 	%fd228, %fd226, %fd227;
	st.f64 	[%SP+496], %fd228;
	.loc	1 9 5
	ld.f64 	%fd229, [%SP+504];
	ld.f64 	%fd230, [%SP+520];
	add.f64 	%fd231, %fd229, %fd230;
	st.f64 	[%SP+504], %fd231;
	.loc	1 10 5
	ld.f64 	%fd232, [%SP+496];
	ld.f64 	%fd233, [%SP+504];
tmp58:
	.loc	1 96 19
	st.f64 	[%rd37+8], %fd233;
	st.f64 	[%rd37], %fd232;
tmp59:

	.loc	1 91 56
	add.s32 	%r6, %r5, 1;
tmp60:
	mov.u32 	%r86, %r6;
tmp61:
	bra.uni 	BB1_3;
tmp62:

BB1_6:

BB1_7:
	.loc	1 99 1
	ret;
tmp63:
func_end1:
}

.func  (.param .b64 func_retval0) sqrt(
	.param .b64 sqrt_param_0
)
{
	.reg .f64 	%fd<3>;


	ld.param.f64 	%fd1, [sqrt_param_0];
	sqrt.rn.f64 	%fd2, %fd1;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

.func  (.param .b64 func_retval0) sin(
	.param .b64 sin_param_0
)
{
	.local .align 4 .b8 	__local_depot3[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<16>;
	.reg .b32 	%r<14>;
	.reg .f64 	%fd<47>;
	.reg .b64 	%rd<7>;


	mov.u64 	%SPL, __local_depot3;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd14, [sin_param_0];
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd14;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd14;
	}
	and.b32  	%r4, %r3, 2147483647;
	setp.eq.s32	%p4, %r4, 2146435072;
	mov.pred 	%p3, 0;
	not.pred 	%p5, %p4;
	mov.pred 	%p15, %p3;
	@%p5 bra 	BB3_2;
	bra.uni 	BB3_1;

BB3_1:
	setp.eq.s32	%p1, %r1, 0;
	mov.pred 	%p15, %p1;

BB3_2:
	mov.pred 	%p2, %p15;
	not.pred 	%p6, %p2;
	mov.f64 	%fd42, %fd14;
	@%p6 bra 	BB3_4;
	bra.uni 	BB3_3;

BB3_3:
	mov.f64 	%fd15, 0d0000000000000000;
	mul.rn.f64 	%fd1, %fd14, %fd15;
	mov.f64 	%fd42, %fd1;

BB3_4:
	mov.f64 	%fd2, %fd42;
	mul.f64 	%fd16, %fd2, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r5, %fd16;
	st.u32 	[%SP+0], %r5;
	ld.u32 	%r6, [%SP+0];
	cvt.rn.f64.s32	%fd17, %r6;
	neg.f64 	%fd18, %fd17;
	mov.f64 	%fd19, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd20, %fd18, %fd19, %fd2;
	neg.f64 	%fd21, %fd17;
	mov.f64 	%fd22, 0d3C91A62633145C00;
	fma.rn.f64 	%fd23, %fd21, %fd22, %fd20;
	neg.f64 	%fd24, %fd17;
	mov.f64 	%fd25, 0d397B839A252049C0;
	fma.rn.f64 	%fd3, %fd24, %fd25, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd2;
	}
	and.b32  	%r8, %r7, 2147483647;
	setp.ge.s32	%p7, %r8, 1105199104;
	not.pred 	%p8, %p7;
	mov.f64 	%fd43, %fd3;
	@%p8 bra 	BB3_6;
	bra.uni 	BB3_5;

BB3_5:
	add.u64 	%rd2, %SP, 0;
	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd4, [retval0+0];
	
	//{
	}// Callseq End 7
	mov.f64 	%fd43, %fd4;

BB3_6:
	mov.f64 	%fd5, %fd43;
	ld.u32 	%r2, [%SP+0];
	and.b32  	%r9, %r2, 1;
	mul.lo.s32 	%r10, %r9, 8;
	mov.u64 	%rd3, __cudart_sin_cos_coeffs;
	cvta.const.u64 	%rd4, %rd3;
	cvt.s64.s32	%rd5, %r10;
	shl.b64 	%rd6, %rd5, 3;
	add.s64 	%rd1, %rd4, %rd6;
	mul.rn.f64 	%fd6, %fd5, %fd5;
	and.b32  	%r11, %r2, 1;
	setp.ne.s32	%p9, %r11, 0;
	not.pred 	%p10, %p9;
	@%p10 bra 	BB3_8;
	bra.uni 	BB3_7;

BB3_7:
	mov.f64 	%fd27, 0dBDA8FF8320FD8164;
	mov.f64 	%fd44, %fd27;
	bra.uni 	BB3_9;

BB3_8:
	mov.f64 	%fd26, 0d3DE5DB65F9785EBA;
	mov.f64 	%fd44, %fd26;

BB3_9:
	mov.f64 	%fd7, %fd44;
	ld.f64 	%fd28, [%rd1+8];
	fma.rn.f64 	%fd29, %fd7, %fd6, %fd28;
	ld.f64 	%fd30, [%rd1+16];
	fma.rn.f64 	%fd31, %fd29, %fd6, %fd30;
	ld.f64 	%fd32, [%rd1+24];
	fma.rn.f64 	%fd33, %fd31, %fd6, %fd32;
	ld.f64 	%fd34, [%rd1+32];
	fma.rn.f64 	%fd35, %fd33, %fd6, %fd34;
	ld.f64 	%fd36, [%rd1+40];
	fma.rn.f64 	%fd37, %fd35, %fd6, %fd36;
	ld.f64 	%fd38, [%rd1+48];
	fma.rn.f64 	%fd8, %fd37, %fd6, %fd38;
	fma.rn.f64 	%fd9, %fd8, %fd5, %fd5;
	and.b32  	%r12, %r2, 1;
	setp.ne.s32	%p11, %r12, 0;
	not.pred 	%p12, %p11;
	mov.f64 	%fd45, %fd9;
	@%p12 bra 	BB3_11;
	bra.uni 	BB3_10;

BB3_10:
	mov.f64 	%fd39, 0d3FF0000000000000;
	fma.rn.f64 	%fd10, %fd8, %fd6, %fd39;
	mov.f64 	%fd45, %fd10;

BB3_11:
	mov.f64 	%fd11, %fd45;
	and.b32  	%r13, %r2, 2;
	setp.ne.s32	%p13, %r13, 0;
	not.pred 	%p14, %p13;
	mov.f64 	%fd46, %fd11;
	@%p14 bra 	BB3_13;
	bra.uni 	BB3_12;

BB3_12:
	mov.f64 	%fd40, 0d0000000000000000;
	mov.f64 	%fd41, 0dBFF0000000000000;
	fma.rn.f64 	%fd12, %fd11, %fd41, %fd40;
	mov.f64 	%fd46, %fd12;

BB3_13:
	mov.f64 	%fd13, %fd46;
	st.param.f64	[func_retval0+0], %fd13;
	ret;
}

.func  (.param .b64 func_retval0) cos(
	.param .b64 cos_param_0
)
{
	.local .align 4 .b8 	__local_depot4[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<16>;
	.reg .b32 	%r<15>;
	.reg .f64 	%fd<47>;
	.reg .b64 	%rd<7>;


	mov.u64 	%SPL, __local_depot4;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd14, [cos_param_0];
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd14;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd14;
	}
	and.b32  	%r4, %r3, 2147483647;
	setp.eq.s32	%p4, %r4, 2146435072;
	mov.pred 	%p3, 0;
	not.pred 	%p5, %p4;
	mov.pred 	%p15, %p3;
	@%p5 bra 	BB4_2;
	bra.uni 	BB4_1;

BB4_1:
	setp.eq.s32	%p1, %r1, 0;
	mov.pred 	%p15, %p1;

BB4_2:
	mov.pred 	%p2, %p15;
	not.pred 	%p6, %p2;
	mov.f64 	%fd42, %fd14;
	@%p6 bra 	BB4_4;
	bra.uni 	BB4_3;

BB4_3:
	mov.f64 	%fd15, 0d0000000000000000;
	mul.rn.f64 	%fd1, %fd14, %fd15;
	mov.f64 	%fd42, %fd1;

BB4_4:
	mov.f64 	%fd2, %fd42;
	mul.f64 	%fd16, %fd2, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r5, %fd16;
	st.u32 	[%SP+0], %r5;
	ld.u32 	%r6, [%SP+0];
	cvt.rn.f64.s32	%fd17, %r6;
	neg.f64 	%fd18, %fd17;
	mov.f64 	%fd19, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd20, %fd18, %fd19, %fd2;
	neg.f64 	%fd21, %fd17;
	mov.f64 	%fd22, 0d3C91A62633145C00;
	fma.rn.f64 	%fd23, %fd21, %fd22, %fd20;
	neg.f64 	%fd24, %fd17;
	mov.f64 	%fd25, 0d397B839A252049C0;
	fma.rn.f64 	%fd3, %fd24, %fd25, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd2;
	}
	and.b32  	%r8, %r7, 2147483647;
	setp.ge.s32	%p7, %r8, 1105199104;
	not.pred 	%p8, %p7;
	mov.f64 	%fd43, %fd3;
	@%p8 bra 	BB4_6;
	bra.uni 	BB4_5;

BB4_5:
	add.u64 	%rd2, %SP, 0;
	// Callseq Start 8
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd4, [retval0+0];
	
	//{
	}// Callseq End 8
	mov.f64 	%fd43, %fd4;

BB4_6:
	mov.f64 	%fd5, %fd43;
	ld.u32 	%r9, [%SP+0];
	add.s32 	%r2, %r9, 1;
	and.b32  	%r10, %r2, 1;
	mul.lo.s32 	%r11, %r10, 8;
	mov.u64 	%rd3, __cudart_sin_cos_coeffs;
	cvta.const.u64 	%rd4, %rd3;
	cvt.s64.s32	%rd5, %r11;
	shl.b64 	%rd6, %rd5, 3;
	add.s64 	%rd1, %rd4, %rd6;
	mul.rn.f64 	%fd6, %fd5, %fd5;
	and.b32  	%r12, %r2, 1;
	setp.ne.s32	%p9, %r12, 0;
	not.pred 	%p10, %p9;
	@%p10 bra 	BB4_8;
	bra.uni 	BB4_7;

BB4_7:
	mov.f64 	%fd27, 0dBDA8FF8320FD8164;
	mov.f64 	%fd44, %fd27;
	bra.uni 	BB4_9;

BB4_8:
	mov.f64 	%fd26, 0d3DE5DB65F9785EBA;
	mov.f64 	%fd44, %fd26;

BB4_9:
	mov.f64 	%fd7, %fd44;
	ld.f64 	%fd28, [%rd1+8];
	fma.rn.f64 	%fd29, %fd7, %fd6, %fd28;
	ld.f64 	%fd30, [%rd1+16];
	fma.rn.f64 	%fd31, %fd29, %fd6, %fd30;
	ld.f64 	%fd32, [%rd1+24];
	fma.rn.f64 	%fd33, %fd31, %fd6, %fd32;
	ld.f64 	%fd34, [%rd1+32];
	fma.rn.f64 	%fd35, %fd33, %fd6, %fd34;
	ld.f64 	%fd36, [%rd1+40];
	fma.rn.f64 	%fd37, %fd35, %fd6, %fd36;
	ld.f64 	%fd38, [%rd1+48];
	fma.rn.f64 	%fd8, %fd37, %fd6, %fd38;
	fma.rn.f64 	%fd9, %fd8, %fd5, %fd5;
	and.b32  	%r13, %r2, 1;
	setp.ne.s32	%p11, %r13, 0;
	not.pred 	%p12, %p11;
	mov.f64 	%fd45, %fd9;
	@%p12 bra 	BB4_11;
	bra.uni 	BB4_10;

BB4_10:
	mov.f64 	%fd39, 0d3FF0000000000000;
	fma.rn.f64 	%fd10, %fd8, %fd6, %fd39;
	mov.f64 	%fd45, %fd10;

BB4_11:
	mov.f64 	%fd11, %fd45;
	and.b32  	%r14, %r2, 2;
	setp.ne.s32	%p13, %r14, 0;
	not.pred 	%p14, %p13;
	mov.f64 	%fd46, %fd11;
	@%p14 bra 	BB4_13;
	bra.uni 	BB4_12;

BB4_12:
	mov.f64 	%fd40, 0d0000000000000000;
	mov.f64 	%fd41, 0dBFF0000000000000;
	fma.rn.f64 	%fd12, %fd11, %fd41, %fd40;
	mov.f64 	%fd46, %fd12;

BB4_13:
	mov.f64 	%fd13, %fd46;
	st.param.f64	[func_retval0+0], %fd13;
	ret;
}

.func  (.param .b64 func_retval0) exp(
	.param .b64 exp_param_0
)
{
	.reg .pred 	%p<8>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<17>;
	.reg .f64 	%fd<46>;


	ld.param.f64 	%fd8, [exp_param_0];
	mov.f64 	%fd9, 0d4338000000000000;
	mov.f64 	%fd10, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd11, %fd8, %fd10, %fd9;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd11;
	}
	fma.rn.f64 	%fd12, %fd8, %fd10, %fd9;
	mov.f64 	%fd13, 0dC338000000000000;
	add.rn.f64 	%fd14, %fd12, %fd13;
	mov.f64 	%fd15, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd16, %fd14, %fd15, %fd8;
	mov.f64 	%fd17, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd18, %fd14, %fd17, %fd16;
	mov.f64 	%fd19, 0d3E928AF3FCA213EA;
	mov.f64 	%fd20, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd21, %fd20, %fd18, %fd19;
	mov.f64 	%fd22, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd23, %fd21, %fd18, %fd22;
	mov.f64 	%fd24, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd25, %fd23, %fd18, %fd24;
	mov.f64 	%fd26, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd27, %fd25, %fd18, %fd26;
	mov.f64 	%fd28, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd29, %fd27, %fd18, %fd28;
	mov.f64 	%fd30, 0d3F81111111122322;
	fma.rn.f64 	%fd31, %fd29, %fd18, %fd30;
	mov.f64 	%fd32, 0d3FA55555555502A1;
	fma.rn.f64 	%fd33, %fd31, %fd18, %fd32;
	mov.f64 	%fd34, 0d3FC5555555555511;
	fma.rn.f64 	%fd35, %fd33, %fd18, %fd34;
	mov.f64 	%fd36, 0d3FE000000000000B;
	fma.rn.f64 	%fd37, %fd35, %fd18, %fd36;
	mov.f64 	%fd38, 0d3FF0000000000000;
	fma.rn.f64 	%fd39, %fd37, %fd18, %fd38;
	fma.rn.f64 	%fd1, %fd39, %fd18, %fd38;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd1;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd1;
	}
	shl.b32 	%r4, %r1, 20;
	add.s32 	%r5, %r4, %r3;
	mov.b64 	%fd2, {%r2, %r5};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd8;
	}
	mov.b32 	 %f1, %r6;
	abs.f32 	%f2, %f1;
	setp.lt.f32	%p1, %f2, 0f4086232B;
	not.pred 	%p2, %p1;
	not.pred 	%p3, %p2;
	mov.f64 	%fd45, %fd2;
	@%p3 bra 	BB5_7;
	bra.uni 	BB5_1;

BB5_1:
	setp.lt.f64	%p4, %fd8, 0d0000000000000000;
	not.pred 	%p5, %p4;
	@%p5 bra 	BB5_3;
	bra.uni 	BB5_2;

BB5_2:
	mov.f64 	%fd40, 0d0000000000000000;
	mov.f64 	%fd43, %fd40;
	bra.uni 	BB5_4;

BB5_3:
	add.f64 	%fd3, %fd8, 0d7FF0000000000000;
	mov.f64 	%fd43, %fd3;

BB5_4:
	mov.f64 	%fd4, %fd43;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd8;
	}
	mov.b32 	 %f3, %r7;
	abs.f32 	%f4, %f3;
	setp.lt.f32	%p6, %f4, 0f40874800;
	not.pred 	%p7, %p6;
	mov.f64 	%fd44, %fd4;
	@%p7 bra 	BB5_6;
	bra.uni 	BB5_5;

BB5_5:
	div.s32 	%r8, %r1, 2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r9, %temp}, %fd1;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd1;
	}
	shl.b32 	%r11, %r8, 20;
	add.s32 	%r12, %r10, %r11;
	mov.b64 	%fd41, {%r9, %r12};
	sub.s32 	%r13, %r1, %r8;
	shl.b32 	%r14, %r13, 20;
	add.s32 	%r15, %r14, 1072693248;
	mov.u32 	%r16, 0;
	mov.b64 	%fd42, {%r16, %r15};
	mul.f64 	%fd5, %fd41, %fd42;
	mov.f64 	%fd44, %fd5;

BB5_6:
	mov.f64 	%fd6, %fd44;
	mov.f64 	%fd45, %fd6;

BB5_7:
	mov.f64 	%fd7, %fd45;
	st.param.f64	[func_retval0+0], %fd7;
	ret;
}

.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 16 .b8 	__local_depot6[128];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<15>;
	.reg .b32 	%r<40>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<95>;


	mov.u64 	%SPL, __local_depot6;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd3, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd20, [__internal_trig_reduction_slowpathd_param_1];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r18}, %fd3;
	}
	and.b32  	%r1, %r18, -2147483648;
	shr.u32 	%r19, %r18, 20;
	and.b32  	%r2, %r19, 2047;
	setp.eq.s32	%p1, %r2, 2047;
	not.pred 	%p2, %p1;
	@%p2 bra 	BB6_2;
	bra.uni 	BB6_1;

BB6_1:
	mov.f64 	%fd4, %fd3;
	bra.uni 	BB6_17;

BB6_2:
	sub.s32 	%r3, %r2, 1024;
	mov.b64 	 %rd21, %fd3;
	shl.b64 	%rd22, %rd21, 11;
	or.b64  	%rd1, %rd22, -9223372036854775808;
	shr.u32 	%r20, %r3, 6;
	mov.u32 	%r21, 16;
	sub.s32 	%r4, %r21, %r20;
	mov.u64 	%rd23, 0;
	st.u64 	[%SP+72], %rd23;
	sub.s32 	%r5, %r4, 1;
	mov.u32 	%r36, %r5;

BB6_3:
	mov.u32 	%r6, %r36;
	add.s32 	%r22, %r4, 3;
	mov.u32 	%r23, 18;
	min.s32 	%r24, %r23, %r22;
	setp.lt.s32	%p3, %r6, %r24;
	not.pred 	%p4, %p3;
	@%p4 bra 	BB6_6;
	bra.uni 	BB6_4;

BB6_4:
	mov.u64 	%rd77, __cudart_i2opi_d;
	cvta.const.u64 	%rd78, %rd77;
	cvt.s64.s32	%rd79, %r6;
	shl.b64 	%rd80, %rd79, 3;
	add.s64 	%rd81, %rd78, %rd80;
	ld.u64 	%rd74, [%rd81];
	ld.u64 	%rd76, [%SP+72];
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi, clo, chi;
	mov.b64         {alo,ahi}, %rd74;    
	mov.b64         {blo,bhi}, %rd1;    
	mov.b64         {clo,chi}, %rd76;    
	mad.lo.cc.u32   r0, alo, blo, clo;
	madc.hi.cc.u32  r1, alo, blo, chi;
	madc.hi.u32     r2, alo, bhi,   0;
	mad.lo.cc.u32   r1, alo, bhi,  r1;
	madc.hi.cc.u32  r2, ahi, blo,  r2;
	madc.hi.u32     r3, ahi, bhi,   0;
	mad.lo.cc.u32   r1, ahi, blo,  r1;
	madc.lo.cc.u32  r2, ahi, bhi,  r2;
	addc.u32        r3,  r3,   0;     
	mov.b64         %rd72, {r0,r1};      
	mov.b64         %rd73, {r2,r3};      
	}
	// inline asm
	st.u64 	[%SP+0], %rd72;
	st.u64 	[%SP+8], %rd73;
	ld.u64 	%rd82, [%SP+0];
	ld.u64 	%rd83, [%SP+8];
	st.u64 	[%SP+72], %rd83;
	st.u64 	[%SP+64], %rd82;
	ld.u64 	%rd84, [%SP+64];
	sub.s32 	%r34, %r4, 1;
	sub.s32 	%r35, %r6, %r34;
	cvt.s64.s32	%rd85, %r35;
	shl.b64 	%rd86, %rd85, 3;
	add.u64 	%rd87, %SP, 80;
	add.s64 	%rd88, %rd87, %rd86;
	st.u64 	[%rd88], %rd84;

	add.s32 	%r7, %r6, 1;
	mov.u32 	%r36, %r7;
	bra.uni 	BB6_3;

BB6_6:
	ld.u64 	%rd24, [%SP+72];
	sub.s32 	%r25, %r4, 1;
	sub.s32 	%r26, %r6, %r25;
	cvt.s64.s32	%rd25, %r26;
	shl.b64 	%rd26, %rd25, 3;
	add.u64 	%rd27, %SP, 80;
	add.s64 	%rd28, %rd27, %rd26;
	st.u64 	[%rd28], %rd24;
	and.b32  	%r8, %r3, 63;
	ld.u64 	%rd2, [%SP+96];
	ld.u64 	%rd3, [%SP+104];
	setp.ne.s32	%p5, %r8, 0;
	not.pred 	%p6, %p5;
	mov.u64 	%rd89, %rd2;
	mov.u64 	%rd90, %rd3;
	@%p6 bra 	BB6_8;
	bra.uni 	BB6_7;

BB6_7:
	mov.u32 	%r27, 64;
	sub.s32 	%r28, %r27, %r8;
	shl.b64 	%rd29, %rd3, %r8;
	shr.u64 	%rd30, %rd2, %r28;
	or.b64  	%rd4, %rd29, %rd30;
	shl.b64 	%rd31, %rd2, %r8;
	ld.u64 	%rd32, [%SP+88];
	shr.u64 	%rd33, %rd32, %r28;
	or.b64  	%rd5, %rd31, %rd33;
	mov.u64 	%rd89, %rd5;
	mov.u64 	%rd90, %rd4;

BB6_8:
	mov.u64 	%rd7, %rd90;
	mov.u64 	%rd6, %rd89;
	shr.u64 	%rd34, %rd7, 62;
	cvt.u32.u64	%r29, %rd34;
	shl.b64 	%rd35, %rd7, 2;
	shr.u64 	%rd36, %rd6, 62;
	or.b64  	%rd8, %rd35, %rd36;
	shl.b64 	%rd9, %rd6, 2;
	shr.u64 	%rd37, %rd8, 63;
	cvt.u32.u64	%r9, %rd37;
	add.s32 	%r10, %r29, %r9;
	setp.ne.s32	%p7, %r1, 0;
	not.pred 	%p8, %p7;
	mov.u32 	%r37, %r10;
	@%p8 bra 	BB6_10;
	bra.uni 	BB6_9;

BB6_9:
	neg.s32 	%r11, %r10;
	mov.u32 	%r37, %r11;

BB6_10:
	mov.u32 	%r12, %r37;
	st.u32 	[%rd20], %r12;
	setp.ne.s32	%p9, %r9, 0;
	not.pred 	%p10, %p9;
	mov.u64 	%rd91, %rd9;
	mov.u64 	%rd92, %rd8;
	mov.u32 	%r38, %r1;
	@%p10 bra 	BB6_12;
	bra.uni 	BB6_11;

BB6_11:
	mov.u64 	%rd41, 0;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd41;
	mov.b64         {a2,a3}, %rd41;
	mov.b64         {b0,b1}, %rd9;
	mov.b64         {b2,b3}, %rd8;
	sub.cc.u32      r0, a0, b0; 
	subc.cc.u32     r1, a1, b1; 
	subc.cc.u32     r2, a2, b2; 
	subc.u32        r3, a3, b3; 
	mov.b64         %rd38, {r0,r1};
	mov.b64         %rd39, {r2,r3};
	}
	// inline asm
	st.u64 	[%SP+16], %rd38;
	st.u64 	[%SP+24], %rd39;
	ld.u64 	%rd44, [%SP+16];
	ld.u64 	%rd45, [%SP+24];
	st.u64 	[%SP+72], %rd45;
	st.u64 	[%SP+64], %rd44;
	ld.u64 	%rd10, [%SP+64];
	ld.u64 	%rd11, [%SP+72];
	xor.b32  	%r13, %r1, -2147483648;
	mov.u64 	%rd91, %rd10;
	mov.u64 	%rd92, %rd11;
	mov.u32 	%r38, %r13;

BB6_12:
	mov.u32 	%r14, %r38;
	mov.u64 	%rd13, %rd92;
	mov.u64 	%rd12, %rd91;
	clz.b64 	%r15, %rd13;
	setp.ne.s32	%p11, %r15, 0;
	not.pred 	%p12, %p11;
	mov.u64 	%rd93, %rd13;
	@%p12 bra 	BB6_14;
	bra.uni 	BB6_13;

BB6_13:
	shl.b64 	%rd46, %rd13, %r15;
	mov.u32 	%r30, 64;
	sub.s32 	%r31, %r30, %r15;
	shr.u64 	%rd47, %rd12, %r31;
	or.b64  	%rd14, %rd46, %rd47;
	mov.u64 	%rd93, %rd14;

BB6_14:
	mov.u64 	%rd15, %rd93;
	mov.u64 	%rd51, -3958705157555305931;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi;
	mov.b64         {alo,ahi}, %rd15;   
	mov.b64         {blo,bhi}, %rd51;   
	mul.lo.u32      r0, alo, blo;    
	mul.hi.u32      r1, alo, blo;    
	mad.lo.cc.u32   r1, alo, bhi, r1;
	madc.hi.u32     r2, alo, bhi,  0;
	mad.lo.cc.u32   r1, ahi, blo, r1;
	madc.hi.cc.u32  r2, ahi, blo, r2;
	madc.hi.u32     r3, ahi, bhi,  0;
	mad.lo.cc.u32   r2, ahi, bhi, r2;
	addc.u32        r3, r3,  0;      
	mov.b64         %rd48, {r0,r1};     
	mov.b64         %rd49, {r2,r3};     
	}
	// inline asm
	st.u64 	[%SP+32], %rd48;
	st.u64 	[%SP+40], %rd49;
	ld.u64 	%rd52, [%SP+32];
	ld.u64 	%rd53, [%SP+40];
	st.u64 	[%SP+72], %rd53;
	st.u64 	[%SP+64], %rd52;
	ld.u64 	%rd16, [%SP+64];
	ld.u64 	%rd17, [%SP+72];
	setp.gt.s64	%p13, %rd17, 0;
	not.pred 	%p14, %p13;
	mov.u32 	%r39, %r15;
	mov.u64 	%rd94, %rd17;
	@%p14 bra 	BB6_16;
	bra.uni 	BB6_15;

BB6_15:
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd16;
	mov.b64         {a2,a3}, %rd17;
	mov.b64         {b0,b1}, %rd16;
	mov.b64         {b2,b3}, %rd17;
	add.cc.u32      r0, a0, b0; 
	addc.cc.u32     r1, a1, b1; 
	addc.cc.u32     r2, a2, b2; 
	addc.u32        r3, a3, b3; 
	mov.b64         %rd54, {r0,r1};
	mov.b64         %rd55, {r2,r3};
	}
	// inline asm
	st.u64 	[%SP+48], %rd54;
	st.u64 	[%SP+56], %rd55;
	ld.u64 	%rd60, [%SP+48];
	ld.u64 	%rd61, [%SP+56];
	st.u64 	[%SP+72], %rd61;
	st.u64 	[%SP+64], %rd60;
	ld.u64 	%rd18, [%SP+72];
	add.s32 	%r16, %r15, 1;
	mov.u32 	%r39, %r16;
	mov.u64 	%rd94, %rd18;

BB6_16:
	mov.u64 	%rd19, %rd94;
	mov.u32 	%r17, %r39;
	cvt.u64.u32	%rd62, %r14;
	shl.b64 	%rd63, %rd62, 32;
	mov.u32 	%r32, 1022;
	sub.s32 	%r33, %r32, %r17;
	cvt.u64.u32	%rd64, %r33;
	shl.b64 	%rd65, %rd64, 52;
	add.s64 	%rd66, %rd19, 1;
	shr.u64 	%rd67, %rd66, 10;
	add.s64 	%rd68, %rd67, 1;
	shr.u64 	%rd69, %rd68, 1;
	add.s64 	%rd70, %rd65, %rd69;
	or.b64  	%rd71, %rd63, %rd70;
	mov.b64 	 %fd1, %rd71;
	mov.f64 	%fd4, %fd1;

BB6_17:
	mov.f64 	%fd2, %fd4;
	st.param.f64	[func_retval0+0], %fd2;
	ret;
}

	.file	1 "C:/Users/chen.bar/Documents/Visual Studio 2019/cuda/integrateMult/kernel.cu", 1581807410, 3233
	.file	2 "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\include\\vector_types.h", 1571905694, 13615

.section .debug_info {
 .b32 2825
 .b8 2
 .b8 0
 .b32 .debug_abbrev
 .b8 8
 .b8 1

 .b8 108
 .b8 103
 .b8 101
 .b8 110
 .b8 102
 .b8 101
 .b8 58
 .b8 32
 .b8 69
 .b8 68
 .b8 71
 .b8 32
 .b8 53
 .b8 46
 .b8 48

 .b8 0
 .b8 4
 .b8 67
 .b8 58
 .b8 47
 .b8 85
 .b8 115
 .b8 101
 .b8 114
 .b8 115
 .b8 47
 .b8 99
 .b8 104
 .b8 101
 .b8 110
 .b8 46
 .b8 98
 .b8 97
 .b8 114
 .b8 47
 .b8 68
 .b8 111
 .b8 99
 .b8 117
 .b8 109
 .b8 101
 .b8 110
 .b8 116
 .b8 115
 .b8 47
 .b8 86
 .b8 105
 .b8 115
 .b8 117
 .b8 97
 .b8 108
 .b8 32
 .b8 83
 .b8 116
 .b8 117
 .b8 100
 .b8 105
 .b8 111
 .b8 32
 .b8 50
 .b8 48
 .b8 49
 .b8 57
 .b8 47
 .b8 99
 .b8 117
 .b8 100
 .b8 97
 .b8 47
 .b8 105
 .b8 110
 .b8 116
 .b8 101
 .b8 103
 .b8 114
 .b8 97
 .b8 116
 .b8 101
 .b8 77
 .b8 117
 .b8 108
 .b8 116
 .b8 47
 .b8 107
 .b8 101
 .b8 114
 .b8 110
 .b8 101
 .b8 108
 .b8 46
 .b8 99
 .b8 117

 .b8 0
 .b64 0
 .b32 .debug_line
 .b8 67
 .b8 58
 .b8 92
 .b8 85
 .b8 115
 .b8 101
 .b8 114
 .b8 115
 .b8 92
 .b8 99
 .b8 104
 .b8 101
 .b8 110
 .b8 46
 .b8 98
 .b8 97
 .b8 114
 .b8 92
 .b8 68
 .b8 111
 .b8 99
 .b8 117
 .b8 109
 .b8 101
 .b8 110
 .b8 116
 .b8 115
 .b8 92
 .b8 86
 .b8 105
 .b8 115
 .b8 117
 .b8 97
 .b8 108
 .b8 32
 .b8 83
 .b8 116
 .b8 117
 .b8 100
 .b8 105
 .b8 111
 .b8 32
 .b8 50
 .b8 48
 .b8 49
 .b8 57
 .b8 92
 .b8 99
 .b8 117
 .b8 100
 .b8 97
 .b8 92
 .b8 105
 .b8 110
 .b8 116
 .b8 101
 .b8 103
 .b8 114
 .b8 97
 .b8 116
 .b8 101
 .b8 77
 .b8 117
 .b8 108
 .b8 116

 .b8 0
 .b8 2

 .b8 95
 .b8 90
 .b8 112
 .b8 108
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 83
 .b8 95

 .b8 0
 .b8 95
 .b8 90
 .b8 112
 .b8 108
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 83
 .b8 95

 .b8 0
 .b8 1
 .b8 6
 .b32 240
 .b8 1
 .b8 3

 .b8 97

 .b8 0
 .b8 1
 .b8 6
 .b32 240
 .b8 3

 .b8 98

 .b8 0
 .b8 1
 .b8 6
 .b32 240
 .b8 0
 .b8 4

 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50

 .b8 0
 .b8 16
 .b8 2
 .b16 334
 .b8 5

 .b8 120

 .b8 0
 .b32 278
 .b8 2
 .b16 336
 .b8 0
 .b8 1
 .b8 5

 .b8 121

 .b8 0
 .b32 278
 .b8 2
 .b16 336
 .b8 8
 .b8 1
 .b8 0
 .b8 6

 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101

 .b8 0
 .b8 4
 .b8 8
 .b8 2

 .b8 95
 .b8 90
 .b8 100
 .b8 118
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 83
 .b8 95

 .b8 0
 .b8 95
 .b8 90
 .b8 100
 .b8 118
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 83
 .b8 95

 .b8 0
 .b8 1
 .b8 19
 .b32 240
 .b8 1
 .b8 3

 .b8 97

 .b8 0
 .b8 1
 .b8 19
 .b32 240
 .b8 3

 .b8 98

 .b8 0
 .b8 1
 .b8 19
 .b32 240
 .b8 7

 .b8 8

 .b8 99

 .b8 0
 .b8 1
 .b8 21
 .b32 240
 .b8 0
 .b8 0
 .b8 2

 .b8 95
 .b8 90
 .b8 109
 .b8 108
 .b8 100
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50

 .b8 0
 .b8 95
 .b8 90
 .b8 109
 .b8 108
 .b8 100
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50

 .b8 0
 .b8 1
 .b8 27
 .b32 240
 .b8 1
 .b8 3

 .b8 97

 .b8 0
 .b8 1
 .b8 27
 .b32 278
 .b8 3

 .b8 98

 .b8 0
 .b8 1
 .b8 27
 .b32 240
 .b8 0
 .b8 2

 .b8 95
 .b8 90
 .b8 109
 .b8 108
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 83
 .b8 95

 .b8 0
 .b8 95
 .b8 90
 .b8 109
 .b8 108
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 83
 .b8 95

 .b8 0
 .b8 1
 .b8 34
 .b32 240
 .b8 1
 .b8 3

 .b8 97

 .b8 0
 .b8 1
 .b8 34
 .b32 240
 .b8 3

 .b8 98

 .b8 0
 .b8 1
 .b8 34
 .b32 240
 .b8 7

 .b8 8

 .b8 116
 .b8 109
 .b8 112
 .b8 86
 .b8 97
 .b8 114

 .b8 0
 .b8 1
 .b8 36
 .b32 240
 .b8 0
 .b8 0
 .b8 2

 .b8 95
 .b8 90
 .b8 49
 .b8 51
 .b8 99
 .b8 111
 .b8 109
 .b8 112
 .b8 108
 .b8 101
 .b8 120
 .b8 83
 .b8 113
 .b8 117
 .b8 97
 .b8 114
 .b8 101
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50

 .b8 0
 .b8 95
 .b8 90
 .b8 49
 .b8 51
 .b8 99
 .b8 111
 .b8 109
 .b8 112
 .b8 108
 .b8 101
 .b8 120
 .b8 83
 .b8 113
 .b8 117
 .b8 97
 .b8 114
 .b8 101
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50

 .b8 0
 .b8 1
 .b8 43
 .b32 240
 .b8 1
 .b8 3

 .b8 97

 .b8 0
 .b8 1
 .b8 43
 .b32 240
 .b8 7

 .b8 8

 .b8 116
 .b8 109
 .b8 112
 .b8 86
 .b8 97
 .b8 114

 .b8 0
 .b8 1
 .b8 45
 .b32 278
 .b8 0
 .b8 0
 .b8 9

 .b8 95
 .b8 90
 .b8 49
 .b8 49
 .b8 99
 .b8 111
 .b8 109
 .b8 112
 .b8 108
 .b8 101
 .b8 120
 .b8 83
 .b8 113
 .b8 114
 .b8 116
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50

 .b8 0
 .b8 95
 .b8 90
 .b8 49
 .b8 49
 .b8 99
 .b8 111
 .b8 109
 .b8 112
 .b8 108
 .b8 101
 .b8 120
 .b8 83
 .b8 113
 .b8 114
 .b8 116
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50

 .b8 0
 .b8 1
 .b8 51
 .b32 240
 .b8 1
 .b64 func_begin0
 .b64 func_end0
 .b8 1
 .b8 156
 .b8 10

 .b8 97

 .b8 0
 .b8 1
 .b8 51
 .b32 240
 .b8 11
 .b8 3
 .b64 __local_depot0
 .b8 35
 .b8 0

 .b8 6
 .b8 11

 .b64 tmp0
 .b64 tmp3
 .b8 12

 .b8 114

 .b8 0
 .b8 1
 .b8 53
 .b32 278
 .b8 7
 .b8 144
 .b8 176
 .b8 226
 .b8 144
 .b8 179
 .b8 214
 .b8 4
 .b8 2
 .b8 12

 .b8 97
 .b8 98
 .b8 115
 .b8 114
 .b8 122

 .b8 0
 .b8 1
 .b8 53
 .b32 278
 .b8 7
 .b8 144
 .b8 178
 .b8 228
 .b8 144
 .b8 179
 .b8 214
 .b8 4
 .b8 2
 .b8 0
 .b8 0
 .b8 2

 .b8 95
 .b8 90
 .b8 49
 .b8 53
 .b8 99
 .b8 111
 .b8 109
 .b8 112
 .b8 108
 .b8 101
 .b8 120
 .b8 69
 .b8 120
 .b8 112
 .b8 111
 .b8 110
 .b8 101
 .b8 110
 .b8 116
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50

 .b8 0
 .b8 95
 .b8 90
 .b8 49
 .b8 53
 .b8 99
 .b8 111
 .b8 109
 .b8 112
 .b8 108
 .b8 101
 .b8 120
 .b8 69
 .b8 120
 .b8 112
 .b8 111
 .b8 110
 .b8 101
 .b8 110
 .b8 116
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50

 .b8 0
 .b8 1
 .b8 61
 .b32 240
 .b8 1
 .b8 3

 .b8 97

 .b8 0
 .b8 1
 .b8 61
 .b32 240
 .b8 7

 .b8 8

 .b8 101
 .b8 120
 .b8 112
 .b8 114

 .b8 0
 .b8 1
 .b8 63
 .b32 278
 .b8 0
 .b8 0
 .b8 2

 .b8 95
 .b8 90
 .b8 49
 .b8 49
 .b8 99
 .b8 111
 .b8 109
 .b8 112
 .b8 108
 .b8 101
 .b8 120
 .b8 67
 .b8 111
 .b8 110
 .b8 106
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50

 .b8 0
 .b8 95
 .b8 90
 .b8 49
 .b8 49
 .b8 99
 .b8 111
 .b8 109
 .b8 112
 .b8 108
 .b8 101
 .b8 120
 .b8 67
 .b8 111
 .b8 110
 .b8 106
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50

 .b8 0
 .b8 1
 .b8 70
 .b32 240
 .b8 1
 .b8 3

 .b8 97

 .b8 0
 .b8 1
 .b8 70
 .b32 240
 .b8 0
 .b8 9

 .b8 95
 .b8 90
 .b8 49
 .b8 51
 .b8 105
 .b8 110
 .b8 116
 .b8 101
 .b8 103
 .b8 114
 .b8 97
 .b8 116
 .b8 101
 .b8 77
 .b8 117
 .b8 108
 .b8 116
 .b8 80
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 80
 .b8 75
 .b8 105
 .b8 80
 .b8 75
 .b8 83
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 50
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 50
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 80
 .b8 75
 .b8 100
 .b8 83
 .b8 50
 .b8 95

 .b8 0
 .b8 95
 .b8 90
 .b8 49
 .b8 51
 .b8 105
 .b8 110
 .b8 116
 .b8 101
 .b8 103
 .b8 114
 .b8 97
 .b8 116
 .b8 101
 .b8 77
 .b8 117
 .b8 108
 .b8 116
 .b8 80
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 80
 .b8 75
 .b8 105
 .b8 80
 .b8 75
 .b8 83
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 50
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 50
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 80
 .b8 75
 .b8 100
 .b8 83
 .b8 50
 .b8 95

 .b8 0
 .b8 1
 .b8 76
 .b32 2733
 .b8 1
 .b64 func_begin1
 .b64 func_end1
 .b8 1
 .b8 156
 .b8 10

 .b8 117

 .b8 0
 .b8 1
 .b8 76
 .b32 2789
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_0
 .b8 7
 .b8 10

 .b8 117
 .b8 68
 .b8 105
 .b8 109

 .b8 0
 .b8 1
 .b8 76
 .b32 2795
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_1
 .b8 7
 .b8 10

 .b8 114
 .b8 97
 .b8 110
 .b8 100
 .b8 80
 .b8 104
 .b8 97
 .b8 115
 .b8 101

 .b8 0
 .b8 1
 .b8 76
 .b32 2806
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_2
 .b8 7
 .b8 10

 .b8 101
 .b8 108

 .b8 0
 .b8 1
 .b8 76
 .b32 2806
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_3
 .b8 7
 .b8 10

 .b8 101
 .b8 108
 .b8 68
 .b8 105
 .b8 109

 .b8 0
 .b8 1
 .b8 76
 .b32 2795
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_4
 .b8 7
 .b8 10

 .b8 116
 .b8 104
 .b8 86
 .b8 77
 .b8 117
 .b8 49

 .b8 0
 .b8 1
 .b8 77
 .b32 2806
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_5
 .b8 7
 .b8 10

 .b8 116
 .b8 104
 .b8 86
 .b8 77
 .b8 117
 .b8 50

 .b8 0
 .b8 1
 .b8 77
 .b32 2806
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_6
 .b8 7
 .b8 10

 .b8 116
 .b8 104
 .b8 86
 .b8 77
 .b8 117
 .b8 51

 .b8 0
 .b8 1
 .b8 77
 .b32 2806
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_7
 .b8 7
 .b8 10

 .b8 116
 .b8 104
 .b8 86
 .b8 67

 .b8 0
 .b8 1
 .b8 77
 .b32 2806
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_8
 .b8 7
 .b8 10

 .b8 116
 .b8 104
 .b8 86
 .b8 68
 .b8 105
 .b8 109

 .b8 0
 .b8 1
 .b8 77
 .b32 2795
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_9
 .b8 7
 .b8 10

 .b8 109
 .b8 105
 .b8 120
 .b8 116
 .b8 117
 .b8 114
 .b8 101
 .b8 77
 .b8 117
 .b8 49

 .b8 0
 .b8 1
 .b8 78
 .b32 2806
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_10
 .b8 7
 .b8 10

 .b8 109
 .b8 105
 .b8 120
 .b8 116
 .b8 117
 .b8 114
 .b8 101
 .b8 77
 .b8 117
 .b8 50

 .b8 0
 .b8 1
 .b8 78
 .b32 2806
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_11
 .b8 7
 .b8 10

 .b8 109
 .b8 105
 .b8 120
 .b8 116
 .b8 117
 .b8 114
 .b8 101
 .b8 77
 .b8 117
 .b8 51

 .b8 0
 .b8 1
 .b8 78
 .b32 2806
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_12
 .b8 7
 .b8 10

 .b8 109
 .b8 105
 .b8 120
 .b8 116
 .b8 117
 .b8 114
 .b8 101
 .b8 67

 .b8 0
 .b8 1
 .b8 78
 .b32 2806
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_13
 .b8 7
 .b8 10

 .b8 109
 .b8 105
 .b8 120
 .b8 116
 .b8 117
 .b8 114
 .b8 101
 .b8 65
 .b8 108
 .b8 112
 .b8 104
 .b8 97

 .b8 0
 .b8 1
 .b8 78
 .b32 2817
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_14
 .b8 7
 .b8 10

 .b8 109
 .b8 105
 .b8 120
 .b8 116
 .b8 117
 .b8 114
 .b8 101
 .b8 68
 .b8 105
 .b8 109

 .b8 0
 .b8 1
 .b8 78
 .b32 2795
 .b8 9
 .b8 3
 .b64 _Z13integrateMultP7double2PKiPKS_S4_S2_S4_S4_S4_S4_S2_S4_S4_S4_S4_PKdS2__param_15
 .b8 7
 .b8 11

 .b64 tmp4
 .b64 tmp63
 .b8 12

 .b8 117
 .b8 68
 .b8 105
 .b8 109
 .b8 73
 .b8 100
 .b8 120

 .b8 0
 .b8 1
 .b8 83
 .b32 2739
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 160
 .b8 4

 .b8 6
 .b8 12

 .b8 115
 .b8 113
 .b8 114
 .b8 116
 .b8 77
 .b8 117

 .b8 0
 .b8 1
 .b8 89
 .b32 240
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 176
 .b8 4

 .b8 6
 .b8 12

 .b8 117
 .b8 73
 .b8 100
 .b8 120

 .b8 0
 .b8 1
 .b8 80
 .b32 2782
 .b8 5
 .b8 144
 .b8 177
 .b8 228
 .b8 149
 .b8 1
 .b8 2
 .b8 12

 .b8 116
 .b8 104
 .b8 86
 .b8 73
 .b8 100
 .b8 120

 .b8 0
 .b8 1
 .b8 87
 .b32 2782
 .b8 5
 .b8 144
 .b8 178
 .b8 228
 .b8 149
 .b8 1
 .b8 2
 .b8 12

 .b8 101
 .b8 73
 .b8 100
 .b8 120

 .b8 0
 .b8 1
 .b8 88
 .b32 2782
 .b8 5
 .b8 144
 .b8 179
 .b8 228
 .b8 149
 .b8 1
 .b8 2
 .b8 11

 .b64 tmp9
 .b64 tmp62
 .b8 13

 .b8 109
 .b8 105
 .b8 120
 .b8 116
 .b8 117
 .b8 114
 .b8 101
 .b8 73
 .b8 100
 .b8 120

 .b8 0
 .b8 1
 .b8 91
 .b32 2782
 .b32 .debug_loc
 .b8 11

 .b64 tmp13
 .b64 tmp62
 .b8 11

 .b64 tmp13
 .b64 tmp59
 .b8 14

 .b32 813
 .b64 tmp14
 .b64 tmp15
 .b8 1
 .b8 93
 .b8 15

 .b32 869
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 144
 .b8 4

 .b8 6
 .b8 0
 .b8 14

 .b32 183
 .b64 tmp16
 .b64 tmp17
 .b8 1
 .b8 93
 .b8 15

 .b32 221
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 176
 .b8 2

 .b8 6
 .b8 15

 .b32 230
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 192
 .b8 2

 .b8 6
 .b8 0
 .b8 16

 .b32 484
 .b32 .debug_ranges
 .b8 1
 .b8 93
 .b8 15

 .b32 544
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 160
 .b8 2

 .b8 6
 .b8 15

 .b32 221
 .b8 11
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 16

 .b8 6
 .b8 15

 .b32 221
 .b8 11
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 112

 .b8 6
 .b8 15

 .b32 230
 .b8 11
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 32

 .b8 6
 .b8 15

 .b32 230
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 128
 .b8 1

 .b8 6
 .b8 17

 .b32 554
 .b8 7
 .b8 144
 .b8 184
 .b8 226
 .b8 144
 .b8 179
 .b8 214
 .b8 4
 .b8 2
 .b8 0
 .b8 14

 .b32 813
 .b64 tmp21
 .b64 tmp22
 .b8 1
 .b8 94
 .b8 15

 .b32 869
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 144
 .b8 2

 .b8 6
 .b8 0
 .b8 14

 .b32 183
 .b64 tmp23
 .b64 tmp24
 .b8 1
 .b8 94
 .b8 15

 .b32 221
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 144
 .b8 1

 .b8 6
 .b8 15

 .b32 230
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 160
 .b8 1

 .b8 6
 .b8 0
 .b8 14

 .b32 484
 .b64 tmp25
 .b64 tmp27
 .b8 1
 .b8 94
 .b8 15

 .b32 544
 .b8 11
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 0

 .b8 6
 .b8 17

 .b32 554
 .b8 7
 .b8 144
 .b8 184
 .b8 232
 .b8 144
 .b8 179
 .b8 214
 .b8 4
 .b8 2
 .b8 0
 .b8 14

 .b32 813
 .b64 tmp30
 .b64 tmp31
 .b8 1
 .b8 95
 .b8 15

 .b32 869
 .b8 11
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 48

 .b8 6
 .b8 0
 .b8 14

 .b32 183
 .b64 tmp32
 .b64 tmp33
 .b8 1
 .b8 95
 .b8 15

 .b32 221
 .b8 11
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 64

 .b8 6
 .b8 15

 .b32 230
 .b8 11
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 80

 .b8 6
 .b8 0
 .b8 14

 .b32 484
 .b64 tmp34
 .b64 tmp36
 .b8 1
 .b8 95
 .b8 15

 .b32 544
 .b8 11
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 96

 .b8 6
 .b8 17

 .b32 554
 .b8 7
 .b8 144
 .b8 182
 .b8 240
 .b8 144
 .b8 179
 .b8 214
 .b8 4
 .b8 2
 .b8 0
 .b8 14

 .b32 356
 .b64 tmp40
 .b64 tmp41
 .b8 1
 .b8 96
 .b8 15

 .b32 392
 .b8 8
 .b8 144
 .b8 179
 .b8 226
 .b8 196
 .b8 161
 .b8 230
 .b8 172
 .b8 9
 .b8 2
 .b8 15

 .b32 401
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 176
 .b8 1

 .b8 6
 .b8 0
 .b8 14

 .b32 813
 .b64 tmp42
 .b64 tmp43
 .b8 1
 .b8 96
 .b8 15

 .b32 869
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 192
 .b8 1

 .b8 6
 .b8 0
 .b8 16

 .b32 183
 .b32 .debug_ranges+64
 .b8 1
 .b8 96
 .b8 15

 .b32 221
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 208
 .b8 1

 .b8 6
 .b8 15

 .b32 221
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 240
 .b8 1

 .b8 6
 .b8 15

 .b32 230
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 224
 .b8 1

 .b8 6
 .b8 15

 .b32 230
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 128
 .b8 2

 .b8 6
 .b8 0
 .b8 14

 .b32 725
 .b64 tmp48
 .b64 tmp50
 .b8 1
 .b8 96
 .b8 15

 .b32 789
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 208
 .b8 2

 .b8 6
 .b8 17

 .b32 799
 .b8 8
 .b8 144
 .b8 177
 .b8 234
 .b8 196
 .b8 161
 .b8 230
 .b8 172
 .b8 9
 .b8 2
 .b8 0
 .b8 16

 .b32 411
 .b32 .debug_ranges+112
 .b8 1
 .b8 96
 .b8 15

 .b32 449
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 224
 .b8 2

 .b8 6
 .b8 15

 .b32 326
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 144
 .b8 3

 .b8 6
 .b8 15

 .b32 458
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 240
 .b8 2

 .b8 6
 .b8 15

 .b32 335
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 160
 .b8 3

 .b8 6
 .b8 17

 .b32 468
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 128
 .b8 3

 .b8 6
 .b8 17

 .b32 345
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 176
 .b8 3

 .b8 6
 .b8 0
 .b8 14

 .b32 411
 .b64 tmp55
 .b64 tmp56
 .b8 1
 .b8 96
 .b8 15

 .b32 449
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 192
 .b8 3

 .b8 6
 .b8 15

 .b32 458
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 208
 .b8 3

 .b8 6
 .b8 17

 .b32 468
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 224
 .b8 3

 .b8 6
 .b8 0
 .b8 14

 .b32 183
 .b64 tmp57
 .b64 tmp58
 .b8 1
 .b8 96
 .b8 15

 .b32 221
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 240
 .b8 3

 .b8 6
 .b8 15

 .b32 230
 .b8 12
 .b8 3
 .b64 __local_depot1
 .b8 35
 .b8 128
 .b8 4

 .b8 6
 .b8 0
 .b8 0
 .b8 0
 .b8 0
 .b8 0
 .b8 0
 .b8 18

 .b8 118
 .b8 111
 .b8 105
 .b8 100

 .b8 0
 .b8 19

 .b8 105
 .b8 110
 .b8 116
 .b8 51

 .b8 0
 .b8 12
 .b8 2
 .b8 185
 .b8 20

 .b8 120

 .b8 0
 .b32 2782
 .b8 2
 .b8 187
 .b8 0
 .b8 1
 .b8 20

 .b8 121

 .b8 0
 .b32 2782
 .b8 2
 .b8 187
 .b8 4
 .b8 1
 .b8 20

 .b8 122

 .b8 0
 .b32 2782
 .b8 2
 .b8 187
 .b8 8
 .b8 1
 .b8 0
 .b8 6

 .b8 105
 .b8 110
 .b8 116

 .b8 0
 .b8 5
 .b8 4
 .b8 21

 .b32 240
 .b8 12
 .b8 21

 .b32 2801
 .b8 12
 .b8 22

 .b32 2782
 .b8 21

 .b32 2812
 .b8 12
 .b8 22

 .b32 240
 .b8 21

 .b32 2823
 .b8 12
 .b8 22

 .b32 278
 .b8 0
}
.section .debug_abbrev {
 .b8 1

 .b8 17

 .b8 1

 .b8 37

 .b8 8

 .b8 19

 .b8 11

 .b8 3

 .b8 8

 .b8 17

 .b8 1

 .b8 16

 .b8 6

 .b8 27

 .b8 8

 .b8 0

 .b8 0

 .b8 2

 .b8 46

 .b8 1

 .b8 135
 .b8 64

 .b8 8

 .b8 3

 .b8 8

 .b8 58

 .b8 11

 .b8 59

 .b8 11

 .b8 73

 .b8 19

 .b8 32

 .b8 11

 .b8 0

 .b8 0

 .b8 3

 .b8 5

 .b8 0

 .b8 3

 .b8 8

 .b8 58

 .b8 11

 .b8 59

 .b8 11

 .b8 73

 .b8 19

 .b8 0

 .b8 0

 .b8 4

 .b8 19

 .b8 1

 .b8 3

 .b8 8

 .b8 11

 .b8 11

 .b8 58

 .b8 11

 .b8 59

 .b8 5

 .b8 0

 .b8 0

 .b8 5

 .b8 13

 .b8 0

 .b8 3

 .b8 8

 .b8 73

 .b8 19

 .b8 58

 .b8 11

 .b8 59

 .b8 5

 .b8 56

 .b8 11

 .b8 50

 .b8 11

 .b8 0

 .b8 0

 .b8 6

 .b8 36

 .b8 0

 .b8 3

 .b8 8

 .b8 62

 .b8 11

 .b8 11

 .b8 11

 .b8 0

 .b8 0

 .b8 7

 .b8 11

 .b8 1

 .b8 0

 .b8 0

 .b8 8

 .b8 52

 .b8 0

 .b8 3

 .b8 8

 .b8 58

 .b8 11

 .b8 59

 .b8 11

 .b8 73

 .b8 19

 .b8 0

 .b8 0

 .b8 9

 .b8 46

 .b8 1

 .b8 135
 .b8 64

 .b8 8

 .b8 3

 .b8 8

 .b8 58

 .b8 11

 .b8 59

 .b8 11

 .b8 73

 .b8 19

 .b8 63

 .b8 12

 .b8 17

 .b8 1

 .b8 18

 .b8 1

 .b8 64

 .b8 10

 .b8 0

 .b8 0

 .b8 10

 .b8 5

 .b8 0

 .b8 3

 .b8 8

 .b8 58

 .b8 11

 .b8 59

 .b8 11

 .b8 73

 .b8 19

 .b8 2

 .b8 10

 .b8 51

 .b8 11

 .b8 0

 .b8 0

 .b8 11

 .b8 11

 .b8 1

 .b8 17

 .b8 1

 .b8 18

 .b8 1

 .b8 0

 .b8 0

 .b8 12

 .b8 52

 .b8 0

 .b8 3

 .b8 8

 .b8 58

 .b8 11

 .b8 59

 .b8 11

 .b8 73

 .b8 19

 .b8 2

 .b8 10

 .b8 51

 .b8 11

 .b8 0

 .b8 0

 .b8 13

 .b8 52

 .b8 0

 .b8 3

 .b8 8

 .b8 58

 .b8 11

 .b8 59

 .b8 11

 .b8 73

 .b8 19

 .b8 2

 .b8 6

 .b8 0

 .b8 0

 .b8 14

 .b8 29

 .b8 1

 .b8 49

 .b8 19

 .b8 17

 .b8 1

 .b8 18

 .b8 1

 .b8 88

 .b8 11

 .b8 89

 .b8 11

 .b8 0

 .b8 0

 .b8 15

 .b8 5

 .b8 0

 .b8 49

 .b8 19

 .b8 2

 .b8 10

 .b8 51

 .b8 11

 .b8 0

 .b8 0

 .b8 16

 .b8 29

 .b8 1

 .b8 49

 .b8 19

 .b8 85

 .b8 6

 .b8 88

 .b8 11

 .b8 89

 .b8 11

 .b8 0

 .b8 0

 .b8 17

 .b8 52

 .b8 0

 .b8 49

 .b8 19

 .b8 2

 .b8 10

 .b8 51

 .b8 11

 .b8 0

 .b8 0

 .b8 18

 .b8 59

 .b8 0

 .b8 3

 .b8 8

 .b8 0

 .b8 0

 .b8 19

 .b8 19

 .b8 1

 .b8 3

 .b8 8

 .b8 11

 .b8 11

 .b8 58

 .b8 11

 .b8 59

 .b8 11

 .b8 0

 .b8 0

 .b8 20

 .b8 13

 .b8 0

 .b8 3

 .b8 8

 .b8 73

 .b8 19

 .b8 58

 .b8 11

 .b8 59

 .b8 11

 .b8 56

 .b8 11

 .b8 50

 .b8 11

 .b8 0

 .b8 0

 .b8 21

 .b8 15

 .b8 0

 .b8 73

 .b8 19

 .b8 51

 .b8 11

 .b8 0

 .b8 0

 .b8 22

 .b8 38

 .b8 0

 .b8 73

 .b8 19

 .b8 0

 .b8 0

 .b8 0

}
.section .debug_loc {
 .b64 tmp10
 .b64 tmp11
 .b8 5
 .b8 0
 .b8 144
 .b8 180
 .b8 228
 .b8 149
 .b8 1
 .b64 tmp11
 .b64 tmp12
 .b8 6
 .b8 0
 .b8 144
 .b8 182
 .b8 240
 .b8 200
 .b8 171
 .b8 2
 .b64 tmp12
 .b64 tmp60
 .b8 5
 .b8 0
 .b8 144
 .b8 181
 .b8 228
 .b8 149
 .b8 1
 .b64 tmp60
 .b64 tmp61
 .b8 5
 .b8 0
 .b8 144
 .b8 182
 .b8 228
 .b8 149
 .b8 1
 .b64 tmp61
 .b64 func_end1
 .b8 6
 .b8 0
 .b8 144
 .b8 182
 .b8 240
 .b8 200
 .b8 171
 .b8 2
 .b64 0
 .b64 0
}
.section .debug_ranges {
 .b64 tmp18
 .b64 tmp20
 .b64 tmp28
 .b64 tmp29
 .b64 tmp37
 .b64 tmp38
 .b64 0
 .b64 0
 .b64 tmp44
 .b64 tmp45
 .b64 tmp46
 .b64 tmp47
 .b64 0
 .b64 0
 .b64 tmp51
 .b64 tmp52
 .b64 tmp53
 .b64 tmp54
 .b64 0
 .b64 0
}
.section .debug_pubnames {
 .b32 284
 .b8 2
 .b8 0
 .b32 .debug_info
 .b32 2825
 .b32 570
 .b8 95
 .b8 90
 .b8 49
 .b8 49
 .b8 99
 .b8 111
 .b8 109
 .b8 112
 .b8 108
 .b8 101
 .b8 120
 .b8 83
 .b8 113
 .b8 114
 .b8 116
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 0

 .b32 813
 .b8 95
 .b8 90
 .b8 49
 .b8 49
 .b8 99
 .b8 111
 .b8 109
 .b8 112
 .b8 108
 .b8 101
 .b8 120
 .b8 67
 .b8 111
 .b8 110
 .b8 106
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 0

 .b32 411
 .b8 95
 .b8 90
 .b8 109
 .b8 108
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 83
 .b8 95
 .b8 0

 .b32 288
 .b8 95
 .b8 90
 .b8 100
 .b8 118
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 83
 .b8 95
 .b8 0

 .b32 356
 .b8 95
 .b8 90
 .b8 109
 .b8 108
 .b8 100
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 0

 .b32 183
 .b8 95
 .b8 90
 .b8 112
 .b8 108
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 83
 .b8 95
 .b8 0

 .b32 725
 .b8 95
 .b8 90
 .b8 49
 .b8 53
 .b8 99
 .b8 111
 .b8 109
 .b8 112
 .b8 108
 .b8 101
 .b8 120
 .b8 69
 .b8 120
 .b8 112
 .b8 111
 .b8 110
 .b8 101
 .b8 110
 .b8 116
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 0

 .b32 484
 .b8 95
 .b8 90
 .b8 49
 .b8 51
 .b8 99
 .b8 111
 .b8 109
 .b8 112
 .b8 108
 .b8 101
 .b8 120
 .b8 83
 .b8 113
 .b8 117
 .b8 97
 .b8 114
 .b8 101
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 0

 .b32 879
 .b8 95
 .b8 90
 .b8 49
 .b8 51
 .b8 105
 .b8 110
 .b8 116
 .b8 101
 .b8 103
 .b8 114
 .b8 97
 .b8 116
 .b8 101
 .b8 77
 .b8 117
 .b8 108
 .b8 116
 .b8 80
 .b8 55
 .b8 100
 .b8 111
 .b8 117
 .b8 98
 .b8 108
 .b8 101
 .b8 50
 .b8 80
 .b8 75
 .b8 105
 .b8 80
 .b8 75
 .b8 83
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 50
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 50
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 83
 .b8 52
 .b8 95
 .b8 80
 .b8 75
 .b8 100
 .b8 83
 .b8 50
 .b8 95
 .b8 0

 .b32 0
}
