//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-27506705
// Cuda compilation tools, release 10.2, V10.2.89
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_30
.address_size 64

	// .globl	_Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2_
.const .align 8 .b8 box_min[16];
.const .align 8 .b8 box_max[16];
.const .align 8 .f64 sigt;
.const .align 4 .u32 vSize;
.const .align 4 .u32 lSize;
.const .align 8 .b8 fastConstCopy[32];

.visible .entry _Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2_(
	.param .u64 _Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_0,
	.param .u64 _Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_1,
	.param .u64 _Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_2,
	.param .u64 _Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_3,
	.param .u64 _Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_4,
	.param .u64 _Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_5,
	.param .u64 _Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_6
)
{
	.reg .pred 	%p<12>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<46>;
	.reg .f64 	%fd<168>;
	.reg .b64 	%rd<28>;


	ld.param.u64 	%rd1, [_Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_0];
	ld.param.u64 	%rd2, [_Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_1];
	ld.param.u64 	%rd3, [_Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_2];
	ld.param.u64 	%rd4, [_Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_3];
	ld.param.u64 	%rd5, [_Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_4];
	ld.param.u64 	%rd6, [_Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_5];
	ld.param.u64 	%rd7, [_Z15ff_single2D_noWP7double2S0_S0_PKdS2_S2_S2__param_6];
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %ntid.x;
	mov.u32 	%r10, %tid.x;
	mad.lo.s32 	%r1, %r9, %r8, %r10;
	ld.const.u32 	%r11, [lSize];
	ld.const.u32 	%r2, [vSize];
	mul.lo.s32 	%r12, %r11, %r2;
	setp.ge.s32	%p1, %r1, %r12;
	@%p1 bra 	BB0_17;

	cvta.to.global.u64 	%rd8, %rd4;
	div.s32 	%r3, %r1, %r2;
	rem.s32 	%r4, %r1, %r2;
	mul.wide.s32 	%rd9, %r4, 8;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	cvta.to.global.u64 	%rd11, %rd5;
	add.s64 	%rd12, %rd11, %rd9;
	ld.global.f64 	%fd2, [%rd12];
	cvta.to.global.u64 	%rd13, %rd6;
	add.s64 	%rd14, %rd13, %rd9;
	cvta.to.global.u64 	%rd15, %rd7;
	add.s64 	%rd16, %rd15, %rd9;
	ld.global.f64 	%fd3, [%rd16];
	ld.global.f64 	%fd36, [%rd14];
	setp.gtu.f64	%p2, %fd36, 0d0000000000000000;
	abs.f64 	%fd4, %fd36;
	@%p2 bra 	BB0_3;
	bra.uni 	BB0_2;

BB0_3:
	ld.const.f64 	%fd38, [box_max];
	ld.const.f64 	%fd159, [fastConstCopy];
	sub.f64 	%fd160, %fd38, %fd159;
	bra.uni 	BB0_4;

BB0_2:
	ld.const.f64 	%fd159, [fastConstCopy];
	ld.const.f64 	%fd37, [box_min];
	sub.f64 	%fd160, %fd159, %fd37;

BB0_4:
	div.rn.f64 	%fd11, %fd160, %fd4;
	abs.f64 	%fd12, %fd3;
	setp.gtu.f64	%p3, %fd3, 0d0000000000000000;
	@%p3 bra 	BB0_6;
	bra.uni 	BB0_5;

BB0_6:
	ld.const.f64 	%fd40, [box_max+8];
	ld.const.f64 	%fd161, [fastConstCopy+8];
	sub.f64 	%fd162, %fd40, %fd161;
	bra.uni 	BB0_7;

BB0_5:
	ld.const.f64 	%fd161, [fastConstCopy+8];
	ld.const.f64 	%fd39, [box_min+8];
	sub.f64 	%fd162, %fd161, %fd39;

BB0_7:
	div.rn.f64 	%fd41, %fd162, %fd12;
	min.f64 	%fd42, %fd11, %fd41;
	mul.f64 	%fd43, %fd2, %fd161;
	fma.rn.f64 	%fd44, %fd1, %fd159, %fd43;
	mul.f64 	%fd164, %fd44, 0dC000000000000000;
	ld.const.f64 	%fd45, [sigt];
	mul.f64 	%fd20, %fd42, %fd45;
	neg.f64 	%fd46, %fd20;
	mov.f64 	%fd47, 0d4338000000000000;
	mov.f64 	%fd48, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd49, %fd46, %fd48, %fd47;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5, %temp}, %fd49;
	}
	mov.f64 	%fd50, 0dC338000000000000;
	add.rn.f64 	%fd51, %fd49, %fd50;
	mov.f64 	%fd52, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd53, %fd51, %fd52, %fd46;
	mov.f64 	%fd54, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd55, %fd51, %fd54, %fd53;
	mov.f64 	%fd56, 0d3E928AF3FCA213EA;
	mov.f64 	%fd57, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd58, %fd57, %fd55, %fd56;
	mov.f64 	%fd59, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd60, %fd58, %fd55, %fd59;
	mov.f64 	%fd61, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd62, %fd60, %fd55, %fd61;
	mov.f64 	%fd63, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd64, %fd62, %fd55, %fd63;
	mov.f64 	%fd65, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd66, %fd64, %fd55, %fd65;
	mov.f64 	%fd67, 0d3F81111111122322;
	fma.rn.f64 	%fd68, %fd66, %fd55, %fd67;
	mov.f64 	%fd69, 0d3FA55555555502A1;
	fma.rn.f64 	%fd70, %fd68, %fd55, %fd69;
	mov.f64 	%fd71, 0d3FC5555555555511;
	fma.rn.f64 	%fd72, %fd70, %fd55, %fd71;
	mov.f64 	%fd73, 0d3FE000000000000B;
	fma.rn.f64 	%fd74, %fd72, %fd55, %fd73;
	mov.f64 	%fd75, 0d3FF0000000000000;
	fma.rn.f64 	%fd76, %fd74, %fd55, %fd75;
	fma.rn.f64 	%fd77, %fd76, %fd55, %fd75;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r6, %temp}, %fd77;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd77;
	}
	shl.b32 	%r13, %r5, 20;
	add.s32 	%r14, %r7, %r13;
	mov.b64 	%fd163, {%r6, %r14};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd46;
	}
	mov.b32 	 %f2, %r15;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB0_10;

	setp.gt.f64	%p5, %fd20, 0d8000000000000000;
	mov.f64 	%fd78, 0d7FF0000000000000;
	sub.f64 	%fd79, %fd78, %fd20;
	selp.f64	%fd163, 0d0000000000000000, %fd79, %p5;
	setp.geu.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB0_10;

	shr.u32 	%r16, %r5, 31;
	add.s32 	%r17, %r5, %r16;
	shr.s32 	%r18, %r17, 1;
	shl.b32 	%r19, %r18, 20;
	add.s32 	%r20, %r19, %r7;
	mov.b64 	%fd80, {%r6, %r20};
	sub.s32 	%r21, %r5, %r18;
	shl.b32 	%r22, %r21, 20;
	add.s32 	%r23, %r22, 1072693248;
	mov.u32 	%r24, 0;
	mov.b64 	%fd81, {%r24, %r23};
	mul.f64 	%fd163, %fd80, %fd81;

BB0_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd164;
	}
	add.s32 	%r26, %r25, %r25;
	setp.lt.u32	%p7, %r26, -2038431743;
	@%p7 bra 	BB0_12;

	mov.f64 	%fd82, 0d0000000000000000;
	mul.rn.f64 	%fd164, %fd164, %fd82;

BB0_12:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd164;
	}
	add.s32 	%r28, %r27, 1048576;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd164;
	}
	mov.b64 	%fd83, {%r29, %r28};
	cvt.rni.f64.f64	%fd84, %fd83;
	cvt.rzi.s64.f64	%rd17, %fd84;
	cvt.u32.u64	%r30, %rd17;
	neg.f64 	%fd85, %fd84;
	mov.f64 	%fd86, 0d3FE0000000000000;
	fma.rn.f64 	%fd87, %fd85, %fd86, %fd164;
	mul.f64 	%fd88, %fd87, 0d3CA1A62633145C07;
	mov.f64 	%fd89, 0d400921FB54442D18;
	fma.rn.f64 	%fd90, %fd87, %fd89, %fd88;
	mul.rn.f64 	%fd91, %fd90, %fd90;
	mov.f64 	%fd92, 0d3E21EEA7C1EF8528;
	mov.f64 	%fd93, 0dBDA8FF8320FD8164;
	fma.rn.f64 	%fd94, %fd93, %fd91, %fd92;
	mov.f64 	%fd95, 0dBE927E4F8E06E6D9;
	fma.rn.f64 	%fd96, %fd94, %fd91, %fd95;
	mov.f64 	%fd97, 0d3EFA01A019DDBCE9;
	fma.rn.f64 	%fd98, %fd96, %fd91, %fd97;
	mov.f64 	%fd99, 0dBF56C16C16C15D47;
	fma.rn.f64 	%fd100, %fd98, %fd91, %fd99;
	mov.f64 	%fd101, 0d3FA5555555555551;
	fma.rn.f64 	%fd102, %fd100, %fd91, %fd101;
	mov.f64 	%fd103, 0dBFE0000000000000;
	fma.rn.f64 	%fd104, %fd102, %fd91, %fd103;
	fma.rn.f64 	%fd106, %fd104, %fd91, %fd75;
	mov.f64 	%fd107, 0dBE5AE5F12CB0D246;
	mov.f64 	%fd108, 0d3DE5DB65F9785EBA;
	fma.rn.f64 	%fd109, %fd108, %fd91, %fd107;
	mov.f64 	%fd110, 0d3EC71DE369ACE392;
	fma.rn.f64 	%fd111, %fd109, %fd91, %fd110;
	mov.f64 	%fd112, 0dBF2A01A019DB62A1;
	fma.rn.f64 	%fd113, %fd111, %fd91, %fd112;
	mov.f64 	%fd114, 0d3F81111111110818;
	fma.rn.f64 	%fd115, %fd113, %fd91, %fd114;
	mov.f64 	%fd116, 0dBFC5555555555554;
	fma.rn.f64 	%fd117, %fd115, %fd91, %fd116;
	mov.f64 	%fd118, 0d0000000000000000;
	fma.rn.f64 	%fd119, %fd117, %fd91, %fd118;
	fma.rn.f64 	%fd120, %fd119, %fd90, %fd90;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd120;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd120;
	}
	xor.b32  	%r33, %r31, -2147483648;
	mov.b64 	%fd121, {%r32, %r33};
	and.b64  	%rd18, %rd17, 1;
	setp.eq.b64	%p8, %rd18, 1;
	not.pred 	%p9, %p8;
	selp.f64	%fd165, %fd106, %fd121, %p9;
	selp.f64	%fd167, %fd120, %fd106, %p9;
	and.b32  	%r34, %r30, 2;
	setp.eq.s32	%p10, %r34, 0;
	@%p10 bra 	BB0_14;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd167;
	}
	xor.b32  	%r36, %r35, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd167;
	}
	mov.b64 	%fd167, {%r37, %r36};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd165;
	}
	xor.b32  	%r39, %r38, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd165;
	}
	mov.b64 	%fd165, {%r40, %r39};

BB0_14:
	fma.rn.f64 	%fd33, %fd165, %fd75, %fd118;
	cvt.rzi.f64.f64	%fd124, %fd164;
	setp.neu.f64	%p11, %fd164, %fd124;
	@%p11 bra 	BB0_16;

	mul.rn.f64 	%fd167, %fd164, %fd118;

BB0_16:
	mad.lo.s32 	%r41, %r2, %r3, %r4;
	cvta.to.global.u64 	%rd19, %rd3;
	mul.wide.s32 	%rd20, %r41, 16;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.v2.f64 	{%fd126, %fd127}, [%rd21];
	ld.const.f64 	%fd130, [fastConstCopy+24];
	mul.f64 	%fd131, %fd127, %fd130;
	neg.f64 	%fd132, %fd131;
	ld.const.f64 	%fd133, [fastConstCopy+16];
	fma.rn.f64 	%fd134, %fd126, %fd133, %fd132;
	mul.f64 	%fd135, %fd163, %fd134;
	mul.f64 	%fd136, %fd127, %fd133;
	fma.rn.f64 	%fd137, %fd126, %fd130, %fd136;
	mul.f64 	%fd138, %fd163, %fd137;
	cvta.to.global.u64 	%rd22, %rd2;
	mul.wide.s32 	%rd23, %r3, 16;
	add.s64 	%rd24, %rd22, %rd23;
	ld.global.v2.f64 	{%fd139, %fd140}, [%rd24];
	mul.f64 	%fd143, %fd167, %fd140;
	neg.f64 	%fd144, %fd143;
	fma.rn.f64 	%fd145, %fd33, %fd139, %fd144;
	mul.f64 	%fd146, %fd167, %fd139;
	fma.rn.f64 	%fd147, %fd33, %fd140, %fd146;
	mul.f64 	%fd148, %fd138, %fd147;
	neg.f64 	%fd149, %fd148;
	fma.rn.f64 	%fd150, %fd145, %fd135, %fd149;
	mul.f64 	%fd151, %fd135, %fd147;
	fma.rn.f64 	%fd152, %fd145, %fd138, %fd151;
	cvta.to.global.u64 	%rd25, %rd1;
	mul.wide.s32 	%rd26, %r1, 16;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.v2.f64 	{%fd153, %fd154}, [%rd27];
	add.f64 	%fd157, %fd152, %fd154;
	add.f64 	%fd158, %fd150, %fd153;
	st.global.v2.f64 	[%rd27], {%fd158, %fd157};

BB0_17:
	ret;
}


