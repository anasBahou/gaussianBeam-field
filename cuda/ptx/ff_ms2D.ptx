//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-27506705
// Cuda compilation tools, release 10.2, V10.2.89
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_30
.address_size 64

	// .globl	_Z7ff_ms2DP7double2S0_PKdS2_S2_S2_
.const .align 8 .b8 box_min[16];
.const .align 8 .b8 box_max[16];
.const .align 8 .f64 g_up;
.const .align 8 .f64 g_down1;
.const .align 8 .f64 g_down2;
.const .align 8 .f64 fw;
.const .align 8 .f64 sigt;
.const .align 4 .u32 vSize;
.const .align 4 .u32 lSize;
.const .align 8 .b8 fastConstCopy[48];

.visible .entry _Z7ff_ms2DP7double2S0_PKdS2_S2_S2_(
	.param .u64 _Z7ff_ms2DP7double2S0_PKdS2_S2_S2__param_0,
	.param .u64 _Z7ff_ms2DP7double2S0_PKdS2_S2_S2__param_1,
	.param .u64 _Z7ff_ms2DP7double2S0_PKdS2_S2_S2__param_2,
	.param .u64 _Z7ff_ms2DP7double2S0_PKdS2_S2_S2__param_3,
	.param .u64 _Z7ff_ms2DP7double2S0_PKdS2_S2_S2__param_4,
	.param .u64 _Z7ff_ms2DP7double2S0_PKdS2_S2_S2__param_5
)
{
	.reg .pred 	%p<13>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<45>;
	.reg .f64 	%fd<183>;
	.reg .b64 	%rd<24>;


	ld.param.u64 	%rd1, [_Z7ff_ms2DP7double2S0_PKdS2_S2_S2__param_0];
	ld.param.u64 	%rd2, [_Z7ff_ms2DP7double2S0_PKdS2_S2_S2__param_1];
	ld.param.u64 	%rd3, [_Z7ff_ms2DP7double2S0_PKdS2_S2_S2__param_2];
	ld.param.u64 	%rd4, [_Z7ff_ms2DP7double2S0_PKdS2_S2_S2__param_3];
	ld.param.u64 	%rd5, [_Z7ff_ms2DP7double2S0_PKdS2_S2_S2__param_4];
	ld.param.u64 	%rd6, [_Z7ff_ms2DP7double2S0_PKdS2_S2_S2__param_5];
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r1, %r8, %r7, %r9;
	ld.const.u32 	%r10, [lSize];
	ld.const.u32 	%r2, [vSize];
	mul.lo.s32 	%r11, %r10, %r2;
	setp.ge.s32	%p1, %r1, %r11;
	@%p1 bra 	BB0_20;

	cvta.to.global.u64 	%rd7, %rd3;
	div.s32 	%r3, %r1, %r2;
	rem.s32 	%r12, %r1, %r2;
	mul.wide.s32 	%rd8, %r12, 8;
	add.s64 	%rd9, %rd7, %rd8;
	ld.global.f64 	%fd1, [%rd9];
	cvta.to.global.u64 	%rd10, %rd4;
	add.s64 	%rd11, %rd10, %rd8;
	ld.global.f64 	%fd2, [%rd11];
	cvta.to.global.u64 	%rd12, %rd5;
	add.s64 	%rd13, %rd12, %rd8;
	cvta.to.global.u64 	%rd14, %rd6;
	add.s64 	%rd15, %rd14, %rd8;
	ld.global.f64 	%fd3, [%rd15];
	ld.global.f64 	%fd42, [%rd13];
	setp.gtu.f64	%p2, %fd42, 0d0000000000000000;
	abs.f64 	%fd4, %fd42;
	@%p2 bra 	BB0_3;
	bra.uni 	BB0_2;

BB0_3:
	ld.const.f64 	%fd44, [box_max];
	ld.const.f64 	%fd173, [fastConstCopy];
	sub.f64 	%fd174, %fd44, %fd173;
	bra.uni 	BB0_4;

BB0_2:
	ld.const.f64 	%fd173, [fastConstCopy];
	ld.const.f64 	%fd43, [box_min];
	sub.f64 	%fd174, %fd173, %fd43;

BB0_4:
	div.rn.f64 	%fd11, %fd174, %fd4;
	abs.f64 	%fd12, %fd3;
	setp.gtu.f64	%p3, %fd3, 0d0000000000000000;
	@%p3 bra 	BB0_6;
	bra.uni 	BB0_5;

BB0_6:
	ld.const.f64 	%fd46, [box_max+8];
	ld.const.f64 	%fd175, [fastConstCopy+8];
	sub.f64 	%fd176, %fd46, %fd175;
	bra.uni 	BB0_7;

BB0_5:
	ld.const.f64 	%fd175, [fastConstCopy+8];
	ld.const.f64 	%fd45, [box_min+8];
	sub.f64 	%fd176, %fd175, %fd45;

BB0_7:
	div.rn.f64 	%fd47, %fd176, %fd12;
	min.f64 	%fd48, %fd11, %fd47;
	mul.f64 	%fd49, %fd2, %fd175;
	fma.rn.f64 	%fd50, %fd1, %fd173, %fd49;
	mul.f64 	%fd178, %fd50, 0dC000000000000000;
	ld.const.f64 	%fd51, [sigt];
	mul.f64 	%fd20, %fd48, %fd51;
	neg.f64 	%fd52, %fd20;
	mov.f64 	%fd53, 0d4338000000000000;
	mov.f64 	%fd54, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd55, %fd52, %fd54, %fd53;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd55;
	}
	mov.f64 	%fd56, 0dC338000000000000;
	add.rn.f64 	%fd57, %fd55, %fd56;
	mov.f64 	%fd58, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd59, %fd57, %fd58, %fd52;
	mov.f64 	%fd60, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd61, %fd57, %fd60, %fd59;
	mov.f64 	%fd62, 0d3E928AF3FCA213EA;
	mov.f64 	%fd63, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd64, %fd63, %fd61, %fd62;
	mov.f64 	%fd65, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd66, %fd64, %fd61, %fd65;
	mov.f64 	%fd67, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd68, %fd66, %fd61, %fd67;
	mov.f64 	%fd69, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd70, %fd68, %fd61, %fd69;
	mov.f64 	%fd71, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd72, %fd70, %fd61, %fd71;
	mov.f64 	%fd73, 0d3F81111111122322;
	fma.rn.f64 	%fd74, %fd72, %fd61, %fd73;
	mov.f64 	%fd75, 0d3FA55555555502A1;
	fma.rn.f64 	%fd76, %fd74, %fd61, %fd75;
	mov.f64 	%fd77, 0d3FC5555555555511;
	fma.rn.f64 	%fd78, %fd76, %fd61, %fd77;
	mov.f64 	%fd79, 0d3FE000000000000B;
	fma.rn.f64 	%fd80, %fd78, %fd61, %fd79;
	mov.f64 	%fd81, 0d3FF0000000000000;
	fma.rn.f64 	%fd82, %fd80, %fd61, %fd81;
	fma.rn.f64 	%fd83, %fd82, %fd61, %fd81;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5, %temp}, %fd83;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd83;
	}
	shl.b32 	%r13, %r4, 20;
	add.s32 	%r14, %r6, %r13;
	mov.b64 	%fd177, {%r5, %r14};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd52;
	}
	mov.b32 	 %f2, %r15;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB0_10;

	setp.gt.f64	%p5, %fd20, 0d8000000000000000;
	mov.f64 	%fd84, 0d7FF0000000000000;
	sub.f64 	%fd85, %fd84, %fd20;
	selp.f64	%fd177, 0d0000000000000000, %fd85, %p5;
	setp.geu.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB0_10;

	shr.u32 	%r16, %r4, 31;
	add.s32 	%r17, %r4, %r16;
	shr.s32 	%r18, %r17, 1;
	shl.b32 	%r19, %r18, 20;
	add.s32 	%r20, %r19, %r6;
	mov.b64 	%fd86, {%r5, %r20};
	sub.s32 	%r21, %r4, %r18;
	shl.b32 	%r22, %r21, 20;
	add.s32 	%r23, %r22, 1072693248;
	mov.u32 	%r24, 0;
	mov.b64 	%fd87, {%r24, %r23};
	mul.f64 	%fd177, %fd86, %fd87;

BB0_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd178;
	}
	add.s32 	%r26, %r25, %r25;
	setp.lt.u32	%p7, %r26, -2038431743;
	@%p7 bra 	BB0_12;

	mov.f64 	%fd88, 0d0000000000000000;
	mul.rn.f64 	%fd178, %fd178, %fd88;

BB0_12:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd178;
	}
	add.s32 	%r28, %r27, 1048576;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd178;
	}
	mov.b64 	%fd89, {%r29, %r28};
	cvt.rni.f64.f64	%fd90, %fd89;
	cvt.rzi.s64.f64	%rd16, %fd90;
	cvt.u32.u64	%r30, %rd16;
	neg.f64 	%fd91, %fd90;
	mov.f64 	%fd92, 0d3FE0000000000000;
	fma.rn.f64 	%fd93, %fd91, %fd92, %fd178;
	mul.f64 	%fd94, %fd93, 0d3CA1A62633145C07;
	mov.f64 	%fd95, 0d400921FB54442D18;
	fma.rn.f64 	%fd96, %fd93, %fd95, %fd94;
	mul.rn.f64 	%fd97, %fd96, %fd96;
	mov.f64 	%fd98, 0d3E21EEA7C1EF8528;
	mov.f64 	%fd99, 0dBDA8FF8320FD8164;
	fma.rn.f64 	%fd100, %fd99, %fd97, %fd98;
	mov.f64 	%fd101, 0dBE927E4F8E06E6D9;
	fma.rn.f64 	%fd102, %fd100, %fd97, %fd101;
	mov.f64 	%fd103, 0d3EFA01A019DDBCE9;
	fma.rn.f64 	%fd104, %fd102, %fd97, %fd103;
	mov.f64 	%fd105, 0dBF56C16C16C15D47;
	fma.rn.f64 	%fd106, %fd104, %fd97, %fd105;
	mov.f64 	%fd107, 0d3FA5555555555551;
	fma.rn.f64 	%fd108, %fd106, %fd97, %fd107;
	mov.f64 	%fd109, 0dBFE0000000000000;
	fma.rn.f64 	%fd110, %fd108, %fd97, %fd109;
	fma.rn.f64 	%fd112, %fd110, %fd97, %fd81;
	mov.f64 	%fd113, 0dBE5AE5F12CB0D246;
	mov.f64 	%fd114, 0d3DE5DB65F9785EBA;
	fma.rn.f64 	%fd115, %fd114, %fd97, %fd113;
	mov.f64 	%fd116, 0d3EC71DE369ACE392;
	fma.rn.f64 	%fd117, %fd115, %fd97, %fd116;
	mov.f64 	%fd118, 0dBF2A01A019DB62A1;
	fma.rn.f64 	%fd119, %fd117, %fd97, %fd118;
	mov.f64 	%fd120, 0d3F81111111110818;
	fma.rn.f64 	%fd121, %fd119, %fd97, %fd120;
	mov.f64 	%fd122, 0dBFC5555555555554;
	fma.rn.f64 	%fd123, %fd121, %fd97, %fd122;
	mov.f64 	%fd124, 0d0000000000000000;
	fma.rn.f64 	%fd125, %fd123, %fd97, %fd124;
	fma.rn.f64 	%fd126, %fd125, %fd96, %fd96;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd126;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd126;
	}
	xor.b32  	%r33, %r31, -2147483648;
	mov.b64 	%fd127, {%r32, %r33};
	and.b64  	%rd17, %rd16, 1;
	setp.eq.b64	%p8, %rd17, 1;
	not.pred 	%p9, %p8;
	selp.f64	%fd179, %fd112, %fd127, %p9;
	selp.f64	%fd181, %fd126, %fd112, %p9;
	and.b32  	%r34, %r30, 2;
	setp.eq.s32	%p10, %r34, 0;
	@%p10 bra 	BB0_14;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd181;
	}
	xor.b32  	%r36, %r35, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd181;
	}
	mov.b64 	%fd181, {%r37, %r36};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd179;
	}
	xor.b32  	%r39, %r38, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd179;
	}
	mov.b64 	%fd179, {%r40, %r39};

BB0_14:
	fma.rn.f64 	%fd33, %fd179, %fd81, %fd124;
	cvt.rzi.f64.f64	%fd130, %fd178;
	setp.neu.f64	%p11, %fd178, %fd130;
	@%p11 bra 	BB0_16;

	mul.rn.f64 	%fd181, %fd178, %fd124;

BB0_16:
	ld.const.f64 	%fd132, [fastConstCopy+24];
	mul.f64 	%fd133, %fd2, %fd132;
	ld.const.f64 	%fd134, [fastConstCopy+16];
	fma.rn.f64 	%fd36, %fd1, %fd134, %fd133;
	ld.const.f64 	%fd37, [fw];
	setp.eq.f64	%p12, %fd37, 0d3FF0000000000000;
	ld.const.f64 	%fd38, [g_up];
	@%p12 bra 	BB0_18;
	bra.uni 	BB0_17;

BB0_18:
	ld.const.f64 	%fd146, [g_down2];
	ld.const.f64 	%fd147, [g_down1];
	fma.rn.f64 	%fd148, %fd146, %fd36, %fd147;
	div.rn.f64 	%fd182, %fd38, %fd148;
	bra.uni 	BB0_19;

BB0_17:
	mul.f64 	%fd135, %fd37, %fd38;
	ld.const.f64 	%fd136, [g_down1];
	ld.const.f64 	%fd137, [g_down2];
	fma.rn.f64 	%fd138, %fd137, %fd36, %fd136;
	div.rn.f64 	%fd139, %fd135, %fd138;
	sub.f64 	%fd141, %fd81, %fd37;
	mul.f64 	%fd142, %fd141, %fd38;
	neg.f64 	%fd143, %fd137;
	fma.rn.f64 	%fd144, %fd143, %fd36, %fd136;
	div.rn.f64 	%fd145, %fd142, %fd144;
	add.f64 	%fd182, %fd139, %fd145;

BB0_19:
	sqrt.rn.f64 	%fd149, %fd182;
	mul.f64 	%fd150, %fd177, %fd149;
	cvta.to.global.u64 	%rd18, %rd2;
	mul.wide.s32 	%rd19, %r3, 16;
	add.s64 	%rd20, %rd18, %rd19;
	ld.global.v2.f64 	{%fd151, %fd152}, [%rd20];
	ld.const.f64 	%fd155, [fastConstCopy+40];
	mul.f64 	%fd156, %fd152, %fd155;
	neg.f64 	%fd157, %fd156;
	ld.const.f64 	%fd158, [fastConstCopy+32];
	fma.rn.f64 	%fd159, %fd151, %fd158, %fd157;
	mul.f64 	%fd160, %fd152, %fd158;
	fma.rn.f64 	%fd161, %fd151, %fd155, %fd160;
	mul.f64 	%fd162, %fd181, %fd161;
	neg.f64 	%fd163, %fd162;
	fma.rn.f64 	%fd164, %fd33, %fd159, %fd163;
	cvta.to.global.u64 	%rd21, %rd1;
	mul.wide.s32 	%rd22, %r1, 16;
	add.s64 	%rd23, %rd21, %rd22;
	ld.global.v2.f64 	{%fd165, %fd166}, [%rd23];
	mul.f64 	%fd169, %fd181, %fd159;
	fma.rn.f64 	%fd170, %fd33, %fd161, %fd169;
	fma.rn.f64 	%fd171, %fd150, %fd170, %fd166;
	fma.rn.f64 	%fd172, %fd150, %fd164, %fd165;
	st.global.v2.f64 	[%rd23], {%fd172, %fd171};

BB0_20:
	ret;
}


